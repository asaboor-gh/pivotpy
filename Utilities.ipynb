{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp g_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide_input\n",
    "import pivotpy as pp \n",
    "pp.nav_links(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities\n",
    "\n",
    "> This includes generally useful functions, including running PowerShell commands from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "from collections import namedtuple\n",
    "from subprocess import Popen, PIPE\n",
    "from inspect import getcallargs as gcargs\n",
    "from io import StringIO\n",
    "from itertools import islice # File generator for faster r\n",
    "\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "# Inside packages import to work both with package and jupyter notebook.\n",
    "try:\n",
    "    from pivotpy import vr_parser as vp\n",
    "    from pivotpy import s_plots as sp\n",
    "    from pivotpy import i_plots as ip\n",
    "except:\n",
    "    import pivotpy.vr_parser as vp\n",
    "    import pivotpy.s_plots as sp\n",
    "    import pivotpy.i_plots as ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_file_size(path):\n",
    "    if os.path.isfile(path):\n",
    "        size = os.stat(path).st_size\n",
    "        for unit in ['Bytes','KB','MB','GB','TB']:\n",
    "            if size < 1024.0:\n",
    "                return \"%3.2f %s\" % (size,unit)\n",
    "            size /= 1024.0\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_file_size('Utilities.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from scipy.interpolate import make_interp_spline, BSpline\n",
    "def interpolate_data(x,y,n=10,k=3):\n",
    "    \"\"\"\n",
    "    - Returns interpolated xnew,ynew. If two points are same, it will add 0.1*min(dx>0) to compensate it.\n",
    "    - **Parameters**\n",
    "        - x: 1D array of size p,\n",
    "        - y: ndarray of size p*q*r,....\n",
    "        - n: Number of points to add between two given points.\n",
    "        - k: Polynomial order to interpolate.\n",
    "\n",
    "    - Only axis 0 will be interpolated. If you want general interploation, use `from scipy.interpolate import make_interp_spline, BSpline`\n",
    "\n",
    "    - **General Usage**: K(p),E(p,q) input from bandstructure.\n",
    "        - `Knew,Enew= interpolate_data(K,E,n=10,k=3)`. cubic interploation\n",
    "    \"\"\"\n",
    "    #Add very small values at simliar points to make interpolation work.\n",
    "    ind=[i for i in range(0,len(x)) if x[i-1]==x[i]] #Duplicate indices\n",
    "    xa=np.unique(x)\n",
    "    dx=0.1*np.min(xa[1:]-xa[:-1])\n",
    "    if(ind):\n",
    "        for pt in ind:\n",
    "            x[pt:]=x[pt:]-x[pt]+x[pt-1]+dx\n",
    "    # Now Apply interpolation\n",
    "    xnew=[np.linspace(x[i],x[i+1],n) for i in range(len(x)-1)]\n",
    "    xnew=np.reshape(xnew,(-1))\n",
    "    spl = make_interp_spline(x, y, k=k) #BSpline object\n",
    "    ynew = spl(xnew)\n",
    "    return xnew,ynew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def ps2py(ps_command='Get-ChildItem', exec_type='-Command', path_to_ps='powershell.exe'):\n",
    "    \"\"\"\n",
    "    - Captures powershell output in python.\n",
    "    - **Parameters**\n",
    "        - ps_command: enclose ps_command in ' ' or \" \".\n",
    "        - exec_type : type of execution, default '-Command', could be '-File'.\n",
    "        - path_to_ps: path to powerhell.exe if not added to PATH variables.\n",
    "    \"\"\"\n",
    "    try: # Works on Linux and Windows if PS version > 5.\n",
    "        cmd = ['pwsh', '-ExecutionPolicy', 'Bypass', exec_type, ps_command]\n",
    "        proc = Popen(cmd, stdout=PIPE, stderr=PIPE)\n",
    "    except FileNotFoundError:\n",
    "        try: # Works only on Windows.\n",
    "            cmd = ['powershell', '-ExecutionPolicy', 'Bypass', exec_type, ps_command]\n",
    "            proc = Popen(cmd, stdout=PIPE, stderr=PIPE)\n",
    "        except FileNotFoundError:\n",
    "            # Works in case nothing above works and you know where is executable.\n",
    "            cmd = [path_to_ps, '-ExecutionPolicy', 'Bypass', exec_type, ps_command]\n",
    "            proc = Popen(cmd, stdout=PIPE, stderr=PIPE)\n",
    "\n",
    "    out=[]; #save to out.\n",
    "    while True:\n",
    "        line = proc.stdout.readline()\n",
    "        if line!=b'':\n",
    "            line=line.strip()\n",
    "            u_line=line.decode(\"utf-8\")\n",
    "            out.append(u_line)\n",
    "        else:\n",
    "            break\n",
    "    out=[item for item in out if item!=''] #filter out empty lines\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def ps2std(ps_command='Get-ChildItem', exec_type='-Command', path_to_ps='powershell.exe'):\n",
    "    \"\"\"\n",
    "    - Prints powershell output in python std.\n",
    "    - **Parameters**\n",
    "        - ps_command: enclose ps_command in ' ' or \" \".\n",
    "        - exec_type: type of execution, default '-Command', could be '-File'.\n",
    "        - path_to_ps: path to powerhell.exe if not added to PATH variables.\n",
    "    \"\"\"\n",
    "    out = ps2py(path_to_ps=path_to_ps,exec_type=exec_type,ps_command=ps_command)\n",
    "    for item in out:\n",
    "        print(item)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `ps2std` only outputs returns of powershell to python std.\n",
    "- `ps2py`'s return could be manipulated in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps2std(ps_command='(Get-Process)[0..4]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp=ps2py(ps_command='(Get-Process)[0..4]')\n",
    "pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_child_items(path = os.getcwd(),depth=None,recursive=True,include=None,exclude=None,filesOnly=False,dirsOnly= False):\n",
    "    \"\"\"\n",
    "    - Returns selected directories/files recursively from a parent directory.\n",
    "    - **Parameters**\n",
    "        - path    : path to a parent directory, default is `\".\"`\n",
    "        - depth   : int, subdirectories depth to get recursively, default is None to list all down.\n",
    "        - recursive : If False, only list current directory items, if True,list all items recursively down the file system.\n",
    "        - include: Default is None and includes everything. String of patterns separated by | to keep, could be a regular expression.\n",
    "        - exclude: Default is None and removes nothing. String of patterns separated by | to drop,could be a regular expression.\n",
    "        - filesOnly : Boolean, if True, returns only files.\n",
    "        - dirsOnly  : Boolean, if True, returns only directories.\n",
    "    - **Returns**\n",
    "        - GLOB : Tuple (children,parent), children is list of selected directories/files and parent is given path. Access by index of by `get_child_items().{children,path}`.\n",
    "    \"\"\"\n",
    "    path = os.path.abspath(path) # important\n",
    "    pattern = path + '**/**' # Default pattern\n",
    "    if depth != None and type(depth) == int:\n",
    "        pattern = path + '/'.join(['*' for i in range(depth+1)])\n",
    "        if glob.glob(pattern) == []: #If given depth is more, fall back.\n",
    "            pattern = path + '**/**' # Fallback to default pattern if more depth to cover all.\n",
    "    glob_files = glob.iglob(pattern, recursive=recursive)\n",
    "    if dirsOnly == True:\n",
    "        glob_files = filter(lambda f: os.path.isdir(f),glob_files)\n",
    "    if filesOnly == True:\n",
    "        glob_files = filter(lambda f: os.path.isfile(f),glob_files)\n",
    "    list_dirs=[]\n",
    "    for g_f in glob_files:\n",
    "        list_dirs.append(os.path.relpath(g_f,path))\n",
    "    # Include check\n",
    "    if include:\n",
    "        list_dirs = [l for l in list_dirs if re.search(include,l)]\n",
    "    # Exclude check\n",
    "    if exclude:\n",
    "        list_dirs = [l for l in list_dirs if not re.search(exclude,l)]\n",
    "    # Keep only unique\n",
    "    req_dirs = list(np.unique(list_dirs))\n",
    "    out_files = namedtuple('GLOB',['children','parent'])\n",
    "    return out_files(req_dirs,os.path.abspath(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = get_child_items(path=\"../\",dirsOnly=True,include='Current',exclude='')\n",
    "print(items.parent)\n",
    "items.children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class color:\n",
    "     def bg(text,r,g,b):\n",
    "          \"\"\"Provide r,g,b component in range 0-255\"\"\"\n",
    "          return f\"\\033[48;2;{r};{g};{b}m{text}\\033[00m\"\n",
    "     def fg(text,r,g,b):\n",
    "          \"\"\"Provide r,g,b component in range 0-255\"\"\"\n",
    "          return f\"\\033[38;2;{r};{g};{b}m{text}\\033[00m\"\n",
    "     # Usual Colos\n",
    "     r  = lambda text: f\"\\033[0;91m {text}\\033[00m\"\n",
    "     rb = lambda text: f\"\\033[1;91m {text}\\033[00m\"\n",
    "     g  = lambda text: f\"\\033[0;92m {text}\\033[00m\"\n",
    "     gb = lambda text: f\"\\033[1;92m {text}\\033[00m\"\n",
    "     b  = lambda text: f\"\\033[0;34m {text}\\033[00m\"\n",
    "     bb = lambda text: f\"\\033[1;34m {text}\\033[00m\"\n",
    "     y  = lambda text: f\"\\033[0;93m {text}\\033[00m\"\n",
    "     yb = lambda text: f\"\\033[1;93m {text}\\033[00m\"\n",
    "     m  = lambda text: f\"\\033[0;95m {text}\\033[00m\"\n",
    "     mb = lambda text: f\"\\033[1;95m {text}\\033[00m\"\n",
    "     c  = lambda text: f\"\\033[0;96m {text}\\033[00m\"\n",
    "     cb = lambda text: f\"\\033[1;96m {text}\\033[00m\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `pivotpy.g_utils.color` contains following attributes:          \n",
    " color.r  --> red       \n",
    " color.rb --> red-bold            \n",
    " color.g  --> green           \n",
    " color.gb --> green-bold             \n",
    " color.b  --> blue            \n",
    " color.bb --> blue-bold          \n",
    " color.y  --> yellow           \n",
    " color.yb --> yellow-bold              \n",
    " color.m  --> magenta                \n",
    " color.mb --> magenta-bold                 \n",
    " color.c  --> cyan              \n",
    " color.cb --> cyan-bold    \n",
    "- **Usage**: print(color.r('This is red'))           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class EncodeFromNumpy(json.JSONEncoder):\n",
    "    \"\"\"\n",
    "    - Serializes python/Numpy objects via customizing json encoder.\n",
    "    - **Usage**\n",
    "        - `json.dumps(python_dict, cls=EncodeFromNumpy)` to get json string.\n",
    "        - `json.dump(*args, cls=EncodeFromNumpy)` to create a file.json.\n",
    "    \"\"\"\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return {\n",
    "                \"_kind_\": \"ndarray\",\n",
    "                \"_value_\": obj.tolist()\n",
    "            }\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj,range):\n",
    "            value = list(obj)\n",
    "            return {\n",
    "                \"_kind_\" : \"range\",\n",
    "                \"_value_\" : [value[0],value[-1]+1]\n",
    "            }\n",
    "        return super(EncodeFromNumpy, self).default(obj)\n",
    "\n",
    "\n",
    "\n",
    "class DecodeToNumpy(json.JSONDecoder):\n",
    "    \"\"\"\n",
    "    - Deserilizes JSON object to Python/Numpy's objects.\n",
    "    - **Usage**\n",
    "        - `json.loads(json_string,cls=DecodeToNumpy)` from string, use `json.load()` for file.\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        json.JSONDecoder.__init__(self, object_hook=self.object_hook, *args, **kwargs)\n",
    "\n",
    "    def object_hook(self, obj):\n",
    "        if '_kind_' not in obj:\n",
    "            return obj\n",
    "        kind = obj['_kind_']\n",
    "        if kind == 'ndarray':\n",
    "            return np.array(obj['_value_'])\n",
    "        elif kind == 'range':\n",
    "            value = obj['_value_']\n",
    "            return range(value[0],value[-1])\n",
    "        return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pivotpy as pp\n",
    "vr=pp.export_vasprun(path = \"E:/Research/graphene_example/ISPIN_2/bands/vasprun.xml\" ,skipk=88,elim=[0,5])\n",
    "print(\"ORIGINAL DATA : {}\\n\".format(vr.poscar.to_dict()))\n",
    "s=json.dumps(vr.poscar.to_dict(), cls=EncodeFromNumpy)\n",
    "print(\"JSON STRING : {}\\n\".format(s))\n",
    "s2 = json.loads(s, cls=DecodeToNumpy)\n",
    "print(\"RETRIEVED DATA : {}\".format(s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _g2f(f):\n",
    "    \"\"\"Add kwargs of `_g` as attribute to `f` and assing __doc__.\"\"\"\n",
    "    _map_d = { # Define inside function, otherwise will throw error in runtime.\n",
    "    'sbands': sp.quick_bplot, 'sdos'  : sp.quick_dos_lines, 'scolor': sp.quick_color_lines,\n",
    "    'srgb'  : sp.quick_rgb_lines, 'irgb'  : ip.plotly_rgb_lines, 'idos'  : ip.plotly_dos_lines}\n",
    "    f.__doc__ = '\\n'.join(l for l in _map_d[f.__name__].__doc__.splitlines() if 'path_evr' not in l)\n",
    "    f.kwargs = {k:v for k,v in gcargs(_map_d[f.__name__]).items() if 'path_evr' not in k}\n",
    "    return f\n",
    "\n",
    "class Vasprun:\n",
    "    \"\"\"\n",
    "    - All plotting functions that depend on `export_vasprun` are joined under this class and renamed.\n",
    "    - **Parameters**\n",
    "        - path       : str: path/to/vasprun.xml. Auto picks in CWD.\n",
    "        - skipk      : int: Skip initial kpoints\n",
    "        - elim       : list: Energy range e.g. [-5,5]\n",
    "        - kseg_inds : list: Join broken path at given indices. Could be obtained from `SEG-INDS` if used `trace_kpath`.\n",
    "        - shift_kpath: float: Shift in kpath values for side by side plotting.\n",
    "    - **Attributes**\n",
    "        - data : Return of `export_vasprun` which is auto-picked in plotting methods under this class.\n",
    "    - **Methods**\n",
    "        - sbands    : Shortcut for `quick_bplot`.\n",
    "        - sdos      : Shortcut for `quick_dos_lines`.\n",
    "        - srgb      : Shortcut for `quick_rgb_lines`.\n",
    "        - scolor    : Shortcut for `quick_color_lines`.\n",
    "        - idos      : Shortcut for `plotly_dos_lines`.\n",
    "        - irgb      : Shortcut for `plotly_rgb_lines`.\n",
    "        - Each of above mathods have an attribute `kwargs` which can be accessed, modified and put back as argumnets.\n",
    "    - **Example**\n",
    "        > vasp   = Vasprun(path='./vasprun.xml')\n",
    "        > kwargs = vasp.sbands.kwargs\n",
    "        > Modify kwargs dictionary as you want for input parameters and unpack back in function.\n",
    "        > vasp.sbands(**kwargs)\n",
    "    \"\"\"\n",
    "    def __init__(self,path=None, skipk=None, elim=[], kseg_inds=[], shift_kpath=0):\n",
    "        try:\n",
    "            from IPython import get_ipython\n",
    "            shell = get_ipython().__class__.__name__\n",
    "            if shell == 'ZMQInteractiveShell' or shell =='Shell':\n",
    "                from IPython.display import set_matplotlib_formats\n",
    "                set_matplotlib_formats('svg')\n",
    "        except: pass\n",
    "        self.data = vp.export_vasprun(path=path, skipk=skipk, elim=elim, kseg_inds=kseg_inds, shift_kpath=shift_kpath)\n",
    "\n",
    "    @_g2f\n",
    "    def sbands(self,*args,**kwargs):\n",
    "        return sp.quick_bplot(self.data,*args,**kwargs)\n",
    "    @_g2f\n",
    "    def sdos(self,*args,**kwargs):\n",
    "        return sp.quick_dos_lines(self.data,*args,**kwargs)\n",
    "    @_g2f\n",
    "    def srgb(self,*args,**kwargs):\n",
    "        return sp.quick_rgb_lines(self.data,*args,**kwargs)\n",
    "    @_g2f\n",
    "    def scolor(self,*args,**kwargs):\n",
    "        return sp.quick_color_lines(self.data,*args,**kwargs)\n",
    "    @_g2f\n",
    "    def idos(self,*args,**kwargs):\n",
    "        return ip.plotly_dos_lines(self.data,*args,**kwargs)\n",
    "    @_g2f\n",
    "    def irgb(self,*args,**kwargs):\n",
    "        return ip.plotly_rgb_lines(self.data,*args,**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def nav_links(current_index=0,\n",
    "            doc_url = r\"https://massgh.github.io/pivotpy/\",\n",
    "            items   = [\"Index\",\n",
    "                       \"XmlElementTree\",\n",
    "                       \"StaticPlots\",\n",
    "                       \"InteractivePlots\",\n",
    "                       \"Utilities\",\n",
    "                       \"StructureIO\",\n",
    "                       \"Widgets\"\n",
    "                       ],\n",
    "            horizontal = False,\n",
    "            out_string = False):\n",
    "    from IPython.display import Markdown\n",
    "    links   = [doc_url+item if not 'Index' in item else doc_url for item in items]\n",
    "    style = \"\"\"<style>a{text-decoration: none !important;color:lightkblue;font-weight:bold;}\n",
    "                a:focus,a:active,a:hover{color:hotpink !important;}</style>\\n\"\"\"\n",
    "    md_str = style\n",
    "    for i,(link,item) in enumerate(zip(links,items)):\n",
    "        if current_index == i: item = \"{}●\".format(item)\n",
    "        if not horizontal:\n",
    "            md_str += \"> [&nbsp;`▶` {}&nbsp;]({})  \\n\".format(item,link)\n",
    "        else:\n",
    "            md_str += \"> [&nbsp;`▶` {}&nbsp;]({})\\n\".format(item,link)\n",
    "    if out_string:\n",
    "        return md_str\n",
    "    return Markdown(md_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def export_outcar(path=None):\n",
    "    \"\"\"\n",
    "    - Read potential at ionic sites from OUTCAR.\n",
    "    \"\"\"\n",
    "    if path is None:\n",
    "        path = './OUTCAR'\n",
    "    if not os.path.isfile(path):\n",
    "        return print(\"{} does not exist!\".format(path))\n",
    "    # Raeding it\n",
    "    with open(r'{}'.format(path),'r') as f:\n",
    "        lines = f.readlines()\n",
    "    # Processing\n",
    "    for i,l in enumerate(lines):\n",
    "        if 'NIONS' in l:\n",
    "            N = int(l.split()[-1])\n",
    "            nlines = np.ceil(N/5).astype(int)\n",
    "        if 'electrostatic' in l:\n",
    "            start_index = i+3\n",
    "            stop_index = start_index+nlines\n",
    "        if 'fractional' in l:\n",
    "            first = i+1\n",
    "        if 'vectors are now' in l:\n",
    "            b_first = i+5\n",
    "        if 'NION' in l:\n",
    "            ion_line = l\n",
    "        if 'NKPTS' in l:\n",
    "            kpt_line =l\n",
    "\n",
    "    NKPTS,NKDIMS,NBANDS = [int(v) for v in re.findall(r\"\\d+\",kpt_line)]\n",
    "    NEDOS,NIONS = [int(v) for v in re.findall(r\"\\d+\",ion_line)]\n",
    "    n_kbi = (NKPTS,NBANDS,NIONS)\n",
    "    # Data manipulation\n",
    "    # Potential\n",
    "    data = lines[start_index:stop_index]\n",
    "    initial = np.loadtxt(StringIO(''.join(data[:-1]))).reshape((-1))\n",
    "    last = np.loadtxt(StringIO(data[-1]))\n",
    "    pot_arr = np.hstack([initial,last]).reshape((-1,2))\n",
    "    pot_arr[:,0] = pot_arr[:,0]-1 # Ion index fixing\n",
    "    # Nearest neighbors\n",
    "    pos = lines[first:first+N]\n",
    "    pos_arr = np.loadtxt(StringIO('\\n'.join(pos)))\n",
    "    pos_arr[pos_arr>0.98] = pos_arr[pos_arr>0.98]-1 # Fixing outer layers\n",
    "    # positions and potential\n",
    "    pos_pot = np.hstack([pos_arr,pot_arr[:,1:]])\n",
    "    basis = np.loadtxt(StringIO(''.join(lines[b_first:b_first+3])))\n",
    "    final_dict = {'ion_pot':pot_arr,'positions':pos_arr,'site_pot':pos_pot,'basis':basis[:,:3],'rec_basis':basis[:,3:],'n_kbi':n_kbi}\n",
    "    return vp.Dict2Data(final_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def export_potential(locpot=None,e = True,m = False):\n",
    "    \"\"\"\n",
    "    - Returns Data from LOCPOT and similar structure files like CHG. Loads only single set out of 2/4 magnetization data to avoid performance/memory cost while can load electrostatic and one set of magnetization together.\n",
    "    - **Parameters**\n",
    "        - locpot: path/to/LOCPOT or similar stuructured file like CHG. LOCPOT is auto picked in CWD.\n",
    "        - e     : Electric potential/charge density. Default is True.\n",
    "        - m     : Magnetization density m. Default is False. If True, picks `m` for spin polarized case, and `m_x` for non-colinear case. Additionally it can take 'x','y' and 'z' in case of non-colinear calculations.\n",
    "    - **Exceptions**\n",
    "        - Would raise index error if magnetization density set is not present in LOCPOT/CHG in case `m` is not False.\n",
    "    \"\"\"\n",
    "    if locpot is None:\n",
    "        if os.path.isfile('LOCPOT'):\n",
    "            locpot = 'LOCPOT'\n",
    "        else:\n",
    "            return print('./LOCPOT not found.')\n",
    "    else:\n",
    "        if not os.path.isfile(locpot):\n",
    "            return print(\"File {!r} does not exist!\".format(locpot))\n",
    "    if m not in [True,False,'x','y','z']:\n",
    "        return print(\"m expects one of [True,False,'x','y','z'], got {}\".format(e))\n",
    "    # data fixing after reading islice from file.\n",
    "    def fix_data(islice_gen,shape):\n",
    "        new_gen = (float(l) for line in islice_gen for l in line.split())\n",
    "        COUNT = np.prod(shape).astype(int)\n",
    "        data = np.fromiter(new_gen,dtype=float,count=COUNT) # Count is must for performance\n",
    "        # data written on LOCPOT is in shape of (NGz,NGy,NGx)\n",
    "        N_reshape = [shape[2],shape[1],shape[0]]\n",
    "        data = data.reshape(N_reshape).transpose([2,1,0])\n",
    "        return data\n",
    "    # Reading File\n",
    "    with open(locpot,'r') as f:\n",
    "        lines = []\n",
    "        f.seek(0)\n",
    "        for i in range(8):\n",
    "            lines.append(f.readline())\n",
    "        N = sum([int(v) for v in lines[6].split()])\n",
    "        f.seek(0)\n",
    "        poscar = []\n",
    "        for i in range(N+8):\n",
    "            poscar.append(f.readline())\n",
    "        f.readline() # Empty one\n",
    "        Nxyz = [int(v) for v in f.readline().split()] # Grid line read\n",
    "        nlines = np.ceil(np.prod(Nxyz)/5).astype(int)\n",
    "        #islice is faster generator for reading potential\n",
    "        pot_dict = {}\n",
    "        if e == True:\n",
    "            pot_dict.update({'e':fix_data(islice(f, nlines),Nxyz)})\n",
    "            ignore_set = 0 # Pointer already ahead.\n",
    "        else:\n",
    "            ignore_set = nlines # Needs to move pointer to magnetization\n",
    "        #reading Magnetization if True\n",
    "        ignore_n = np.ceil(N/5).astype(int)+1 #Some kind of useless data\n",
    "        if m == True:\n",
    "            print(\"m = True would pick m_x for non-colinear case, and m for ISPIN=2.\\nUse m='x' for non-colinear or keep in mind that m will refer to m_x.\")\n",
    "            start = ignore_n+ignore_set\n",
    "            pot_dict.update({'m': fix_data(islice(f, start,start+nlines),Nxyz)})\n",
    "        elif m == 'x':\n",
    "            start = ignore_n+ignore_set\n",
    "            pot_dict.update({'m_x': fix_data(islice(f, start,start+nlines),Nxyz)})\n",
    "        elif m == 'y':\n",
    "            start = 2*ignore_n+nlines+ignore_set\n",
    "            pot_dict.update({'m_y': fix_data(islice(f, start,start+nlines),Nxyz)})\n",
    "        elif m == 'z':\n",
    "            start = 3*ignore_n+2*nlines+ignore_set\n",
    "            pot_dict.update({'m_z': fix_data(islice(f, start,start+nlines),Nxyz)})\n",
    "\n",
    "    # Read Info\n",
    "    basis = np.loadtxt(StringIO(''.join(poscar[2:5])))*float(poscar[1].strip())\n",
    "    system = poscar[0].strip()\n",
    "    ElemName = poscar[5].split()\n",
    "    ElemIndex = [int(v) for v in poscar[6].split()]\n",
    "    ElemIndex.insert(0,0)\n",
    "    ElemIndex = list(np.cumsum(ElemIndex))\n",
    "    positions = np.loadtxt(StringIO(''.join(poscar[8:N+9])))\n",
    "\n",
    "    final_dict = dict(SYSTEM=system,ElemName=ElemName,ElemIndex=ElemIndex,basis=basis,positions=positions)\n",
    "    final_dict = {**final_dict,**pot_dict}\n",
    "    return vp.Dict2Data(final_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "class LOCPOT_CHG:\n",
    "    \"\"\"\n",
    "    - Returns Data from LOCPOT and similar structure files like CHG. Loads only single set out of 2/4 magnetization data to avoid performance/memory cost while can load electrostatic and one set of magnetization together.\n",
    "    - **Parameters**\n",
    "        - path: path/to/LOCPOT or similar stuructured file like CHG. LOCPOT is auto picked in CWD.\n",
    "        - e   : Electric potential/charge density. Default is True.\n",
    "        - m   : Magnetization density m. Default is False. If True, picks `m` for spin polarized case, and `m_x` for non-colinear case. Additionally it can take 'x','y' and 'z' in case of non-colinear calculations.\n",
    "    - **Exceptions**\n",
    "        - Would raise index error if magnetization density set is not present in LOCPOT/CHG in case `m` is not False.\n",
    "    \"\"\"\n",
    "    def __init__(self,path=None,e = True,m = False):\n",
    "        try:\n",
    "            from IPython import get_ipython\n",
    "            shell = get_ipython().__class__.__name__\n",
    "            if shell == 'ZMQInteractiveShell' or shell =='Shell':\n",
    "                from IPython.display import set_matplotlib_formats\n",
    "                set_matplotlib_formats('svg')\n",
    "        except: pass\n",
    "        self.path = path # Must be\n",
    "        self.m = m # Required to put in plots.\n",
    "        self.data = export_potential(locpot=path, e=e,m=m)\n",
    "        # DOCS\n",
    "        lines = sp.plot_potential.__doc__.split('\\n')\n",
    "        lines = [l for l in [l for l in lines if 'basis' not in l] if 'e_or_m' not in l]\n",
    "        LOCPOT_CHG.plot_e.__doc__ = '\\n'.join(lines)\n",
    "        LOCPOT_CHG.plot_m.__doc__ = '\\n'.join(lines)\n",
    "\n",
    "    def plot_e(self,operation='mean_z',ax=None,period=None,\n",
    "                 lr_pos=(0.25,0.75),lr_widths = [0.5,0.5],\n",
    "                 labels=(r'$V(z)$',r'$\\langle V \\rangle _{roll}(z)$',r'$\\langle V \\rangle $'),\n",
    "                 colors = ((0,0.2,0.7),'b','r'),annotate=True):\n",
    "        return sp.plot_potential(basis=self.data.basis,e_or_m=self.data.e,operation=operation,\n",
    "                                    ax=ax,period=period,lr_pos=lr_pos,lr_widths=lr_widths,\n",
    "                                    labels=labels,colors=colors,annotate=annotate)\n",
    "\n",
    "    def plot_m(self,operation='mean_z',ax=None,period=None,\n",
    "                lr_pos=(0.25,0.75),lr_widths = [0.5,0.5],\n",
    "                labels=(r'$M(z)$',r'$\\langle M \\rangle _{roll}(z)$',r'$\\langle M \\rangle $'),\n",
    "                colors = ((0,0.2,0.7),'b','r'),annotate=True):\n",
    "        if self.m == True:\n",
    "            e_or_m = self.data.m\n",
    "        elif self.m == 'x':\n",
    "            e_or_m = self.data.m_x\n",
    "        elif self.m == 'y':\n",
    "            e_or_m = self.data.m_y\n",
    "        elif self.m == 'z':\n",
    "            e_or_m = self.data.m_z\n",
    "        else:\n",
    "            return print(\"Magnetization data set does not exist in {}\".format(self.path))\n",
    "        return sp.plot_potential(basis=self.data.basis,e_or_m=e_or_m,operation=operation,\n",
    "                                    ax=ax,period=period,lr_pos=lr_pos,lr_widths=lr_widths,\n",
    "                                    labels=labels,colors=colors,annotate=annotate)\n",
    "\n",
    "    def view_period(self,period_guess=0.25,operation='mean_z',nslice=10,e_or_m=None,):\n",
    "        \"\"\"\n",
    "        - Periodicity check by plotly's interactive plot.\n",
    "        - **Parameters**\n",
    "            - period_guess: Initial guess of period. Default is 0.25. Should be in [0,1].\n",
    "            - operation   : Any of ['mean_x','min_x','max_x','mean_y','min_y','max_y','mean_z','min_z','max_z'].\n",
    "            - nslice      : Default is 10. Number of periods around and including period_guess. e.g. If you give 0.25 as period_guess and nslice is 10, you will get 10 lines of rolling average over given data from where you can choose best fit or try another guess and so on.\n",
    "            - e_or_m      : None by default. Not required in most cases as `view_period()` will try to get data itself from top class in order of `self.data.[e,m,m_x,m_y,m_z]` and if `self.data.e` exists it never goes to others, so you can overwrite this by setting `e_or_m = self.data.[your choice]`.\n",
    "        \"\"\"\n",
    "        pos = period_guess\n",
    "        check = ['mean_x','min_x','max_x','mean_y','min_y','max_y','mean_z','min_z','max_z']\n",
    "        if operation not in check:\n",
    "            return print(\"operation expects any of {!r}, got {}\".format(check,operation))\n",
    "        if e_or_m is None:\n",
    "            try:\n",
    "                data = self.data.e\n",
    "            except:\n",
    "                if self.m == True:\n",
    "                    data = self.data.m\n",
    "                elif self.m == 'x':\n",
    "                    data = self.data.m_x\n",
    "                elif self.m == 'y':\n",
    "                    data = self.data.m_y\n",
    "                elif self.m == 'z':\n",
    "                    data = self.data.m_z\n",
    "                else:\n",
    "                    return print(\"Magnetization data set does not exist in {}\".format(self.path))\n",
    "        else:\n",
    "            data = e_or_m\n",
    "\n",
    "        _opr,_dir = operation.split('_')\n",
    "        if 'z' in _dir:\n",
    "            a1,a2 = 0,0\n",
    "        elif 'y' in _dir:\n",
    "            a1,a2 = 2,0\n",
    "        else:\n",
    "            a1,a2 = 1,1\n",
    "        fig = go.Figure()\n",
    "        _arr = eval(\"data.{}(axis={}).{}(axis={})\".format(_opr,a1,_opr,a2))\n",
    "        N = np.rint(pos*len(_arr)).astype(int)\n",
    "        _range = range(int(N-nslice/2),int(N+nslice/2+1)) # +1 for range.\n",
    "        for div in _range:\n",
    "            if div > 0 and div < len(_arr):\n",
    "                y = np.convolve(_arr+div,np.ones((div,))/div,mode='valid')\n",
    "                x = np.linspace(0,1,len(y))\n",
    "                h_text = [\"{}: {:>5.3f}</br>v: {:>5.3f}\".format(_dir,_h,_v-div) for _h,_v in zip(x,y)]\n",
    "                fig.add_trace(go.Scatter(x=x,y=y,name=\"Roll_av({:>5.3f})\".format(div/len(_arr)),hovertext=h_text))\n",
    "        fig.update_layout(title = self.data.SYSTEM,font=dict(family=\"stix serif\",size=14),\n",
    "                          yaxis = go.layout.YAxis(title_text='No. of Points in Rolling Average'),\n",
    "                          xaxis = go.layout.XAxis(title_text=\"{}({}<sub>max</sub>)\".format(_dir,_dir)))\n",
    "        return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def transform_color(arr,s=1,c=1,b=0,mixing_matrix=None):\n",
    "    \"\"\"\n",
    "    - Color transformation such as brightness, contrast, saturation and mixing of an input color array. `c = -1` would invert color,keeping everything else same.\n",
    "    - **Parameters**\n",
    "        - arr: input array, a single RGB/RGBA color or an array with inner most dimension equal to 3 or 4. e.g. [[[0,1,0,1],[0,0,1,1]]].\n",
    "        - c  : contrast, default is 1. Can be a float in [-1,1].\n",
    "        - s  : saturation, default is 1. Can be a float in [-1,1]. If s = 0, you get a gray scale image.\n",
    "        - b  : brightness, default is 0. Can be a float in [-1,1] or list of three brightnesses for RGB components.\n",
    "        - mixing_matrix: A 3x3 matrix to mix RGB values, such as `pp.color_matrix`.\n",
    "\n",
    "    [Recoloring](https://docs.microsoft.com/en-us/windows/win32/gdiplus/-gdiplus-recoloring-use?redirectedfrom=MSDN)\n",
    "    [Rainmeter](https://docs.rainmeter.net/tips/colormatrix-guide/)\n",
    "    \"\"\"\n",
    "    arr = np.array(arr) # Must\n",
    "    t = (1-c)/2 # For fixing gray scale when contrast is 0.\n",
    "    whiteness = np.array(b)+t # need to clip to 1 and 0 after adding to color.\n",
    "    sr = (1-s)*0.2125 #red saturation from red luminosity\n",
    "    sg = (1-s)*0.7154 #green saturation from green luminosity\n",
    "    sb = (1-s)*0.0721 #blue saturation from blue luminosity\n",
    "    # trans_matrix is multiplied from left, or multiply its transpose from right.\n",
    "    # trans_matrix*color is not normalized but value --> value - int(value) to keep in [0,1].\n",
    "    trans_matrix = np.array([\n",
    "        [c*(sr+s), c*sg,      c*sb],\n",
    "        [c*sr,   c*(sg+s),    c*sb],\n",
    "        [c*sr,     c*sg,  c*(sb+s)]])\n",
    "    if np.ndim(arr) == 1:\n",
    "        new_color = np.dot(trans_matrix,arr)\n",
    "    else:\n",
    "        new_color = np.dot(arr[...,:3],trans_matrix.T)\n",
    "    if mixing_matrix is not None and np.size(mixing_matrix)==9:\n",
    "        new_color = np.dot(new_color,np.transpose(mixing_matrix))\n",
    "    new_color[new_color > 1] = new_color[new_color > 1] - new_color[new_color > 1].astype(int)\n",
    "    new_color = np.clip(new_color + whiteness,a_max=1,a_min=0)\n",
    "    if np.shape(arr)[-1]==4:\n",
    "        axis = len(np.shape(arr))-1 #Add back Alpha value if present\n",
    "        new_color = np.concatenate([new_color,arr[...,3:]],axis=axis)\n",
    "    return new_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt,pivotpy as pp \n",
    "axs = pp.init_figure(nrows=2,ncols=2,figsize=(4.5,2.5))\n",
    "carr = [[[1,0,0,1],[0,1,0,1],[0,0,1,1]]]\n",
    "axs[0,0].imshow(transform_color(arr=carr))\n",
    "axs[0,1].imshow(transform_color(s=0,arr=carr))\n",
    "axs[1,0].imshow(transform_color(b=[-0.5,0,0],arr=carr))\n",
    "axs[1,1].imshow(transform_color(arr=carr,mixing_matrix=pp.color_matrix[:,:3]))\n",
    "for ax,txt in zip(axs.ravel(),['original','s = 0','b = [-0.5,0,0]','mixing_matrix']):\n",
    "    ax.set_title(txt)\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "_ = plt.gcf().suptitle('transform_color(arr,s,c,b,mixing_matrix)',color='b',fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide_input\n",
    "nav_links(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bita511f18cfc7e44c89db72e4d1298f945"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
