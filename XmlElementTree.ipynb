{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp vr_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xml Parser\n",
    "> This parser contains functions to extract data from vasprun.xml. All functions in xml parser can work without arguments if working directory contains `vasprun.xml`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Dic2Dot(dict):\n",
    "    \"\"\"\n",
    "    - Returns dot notation accessible if a dictionary is input.\n",
    "    - It is used to pack all functions in a dictionary.\n",
    "    \"\"\"\n",
    "    def __getattr__(self, name):\n",
    "        return self[name]\n",
    "    def __getstate__(self):\n",
    "        pass  #This is for pickling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parser Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def read_asxml(path=None,suppress_warning=False):\n",
    "    \"\"\"\n",
    "    - Reads a big vasprun.xml file into memory once and then apply commands.\n",
    "    If current folder contains `vasprun.xml` file, it automatically picks it.\n",
    "\n",
    "    - **Parameters**\n",
    "        - path             : Path/To/vasprun.xml\n",
    "        - suppress_warning : False by defualt. Warns about memory usage for large files > 100 MB.\n",
    "    - **Returns**\n",
    "        - xml_data : Xml object to use in other functions\n",
    "    \"\"\"\n",
    "    if(path==None):\n",
    "        path='./vasprun.xml'\n",
    "    import xml.etree.ElementTree as ET\n",
    "    import os\n",
    "    if not os.path.isfile(path):\n",
    "        print(\"File: '{}'' does not exist!\".format(path))\n",
    "        return # This is important to stop further errors.\n",
    "    elif 'vasprun.xml' not in path:\n",
    "        print(\"File should end with 'vasprun.xml', prefixes are allowed.\")\n",
    "        return # This is important to stop further errors.\n",
    "    else:\n",
    "        if suppress_warning == False:\n",
    "            from pivotpy.g_utils import get_file_size,printy,printg\n",
    "            fsize = get_file_size(path)\n",
    "            value = float(fsize.split()[0])\n",
    "            print_str = \"\"\"\n",
    "            File: {} is large ({}).\n",
    "            It may consume a lot of memory (generally 3 times the file size).\n",
    "\n",
    "            An alternative way is to parse vasprun.xml is by using `Vasp2Visual` module in Powershell by command\n",
    "            `pivotpy.load_export('path/to/vasprun.xml'), which runs underlying powershell functions to load data whith\n",
    "            efficient memory managment. It works on Windows/Linux/MacOS if you have powershell core and Vasp2Visual\n",
    "            installed on it.\n",
    "\n",
    "            Hit `Ctrl+C` if you do not get `successful!` prompt in <10 sec, then use `load_export()` instead with\n",
    "            max_filled/max_empty given, default is 10/10 bands above and below VBM.\n",
    "            \"\"\".format(path,fsize)\n",
    "            if 'MB' in fsize and value > 100:\n",
    "                printy(print_str)\n",
    "            elif 'GB' in fsize and value > 1:\n",
    "                printy(print_str)\n",
    "                value = value*1024 # To show in MBs for later Use.\n",
    "        tree = ET.parse(path)\n",
    "        xml_data = tree.getroot()\n",
    "        if suppress_warning == False and value > 100:\n",
    "            printg('\\n      successful!\\n')\n",
    "        return xml_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def exclude_kpts(xml_data=None):\n",
    "    \"\"\"\n",
    "    - Returns number of kpoints to exclude used from IBZKPT.\n",
    "    - **Parameters**\n",
    "        - xml_data : From `read_asxml` function\n",
    "    - **Returns**\n",
    "        - int      : Number of kpoints to exclude.\n",
    "    \"\"\"\n",
    "    if(xml_data==None):\n",
    "        xml_data=read_asxml()\n",
    "    if not xml_data:\n",
    "        return\n",
    "    for kpts in xml_data.iter('varray'):\n",
    "        if(kpts.attrib=={'name': 'weights'}):\n",
    "            weights=[float(arr.text.strip()) for arr in kpts.iter('v')]\n",
    "    exclude=[]\n",
    "    [exclude.append(item) for item in weights if item!=weights[-1]];\n",
    "    skipk=len(exclude) #that much to skip\n",
    "    return skipk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_ispin(xml_data=None):\n",
    "    \"\"\"\n",
    "    - Returns value of ISPIN.\n",
    "    - **Parameters**\n",
    "        - xml_data : From `read_asxml` function\n",
    "    - **Returns**\n",
    "        - int      : Value of ISPIN.\n",
    "    \"\"\"\n",
    "    if(xml_data==None):\n",
    "        xml_data=read_asxml()\n",
    "    if not xml_data:\n",
    "        return\n",
    "    for item in xml_data.iter('i'):\n",
    "        if(item.attrib=={'type': 'int', 'name': 'ISPIN'}):\n",
    "            return int(item.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_summary(xml_data=None):\n",
    "    \"\"\"\n",
    "    - Returns overview of system parameters.\n",
    "    - **Parameters**\n",
    "        - xml_data : From `read_asxml` function\n",
    "    - **Returns**\n",
    "        - dict     : Dictionary that contains system information.\n",
    "    \"\"\"\n",
    "    if(xml_data==None):\n",
    "        xml_data=read_asxml()\n",
    "    if not xml_data:\n",
    "        return\n",
    "    for i_car in xml_data.iter('incar'):\n",
    "        incar={car.attrib['name']:car.text.strip() for car in i_car}\n",
    "    n_ions=[int(atom.text) for atom in xml_data.iter('atoms')][0]\n",
    "    type_ions=[int(atom_types.text) for atom_types in xml_data.iter('types')][0]\n",
    "    elem=[info[0].text.strip() for info in xml_data.iter('rc')]\n",
    "    elem_name=[]; #collect IONS names\n",
    "    [elem_name.append(item) for item in elem[:-type_ions] if item not in elem_name]\n",
    "    elem_index=[0]; #start index\n",
    "    [elem_index.append((int(entry)+elem_index[-1])) for entry in elem[-type_ions:]];\n",
    "    ISPIN=get_ispin(xml_data=xml_data)\n",
    "    # Fields\n",
    "    try:\n",
    "        for pro in xml_data.iter('partial'):\n",
    "            dos_fields=[field.text.strip() for field in pro.iter('field')]\n",
    "            dos_fields = [field for field in dos_fields if 'energy' not in field]\n",
    "    except:\n",
    "        dos_fields = []\n",
    "    for i in xml_data.iter('i'): #efermi for condition required.\n",
    "        if(i.attrib=={'name': 'efermi'}):\n",
    "            efermi=float(i.text)\n",
    "    #Writing information to a dictionary\n",
    "    info_dic={'SYSTEM':incar['SYSTEM'],'NION':n_ions,'TypeION':type_ions,'ElemName':elem_name,'ElemIndex':elem_index,\\\n",
    "        'E_Fermi': efermi,'ISPIN':ISPIN,'fields':dos_fields,'incar':incar}\n",
    "    return Dic2Dot(info_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m \n      successful!\n\u001b[00m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'SYSTEM': 'AlAs',\n",
       " 'NION': 2,\n",
       " 'TypeION': 2,\n",
       " 'ElemName': ['Al', 'As'],\n",
       " 'ElemIndex': [0, 1, 2],\n",
       " 'ISPIN': 1,\n",
       " 'fields': ['s', 'py', 'pz', 'px', 'dxy', 'dyz', 'dz2', 'dxz', 'x2-y2'],\n",
       " 'incar': {'SYSTEM': 'AlAs',\n",
       "  'PREC': 'high',\n",
       "  'ALGO': 'N',\n",
       "  'NELMIN': '7',\n",
       "  'EDIFF': '0.00000100',\n",
       "  'ISMEAR': '0',\n",
       "  'SIGMA': '0.10000000',\n",
       "  'LORBIT': '11',\n",
       "  'KPOINT_BSE': '-1     0     0     0',\n",
       "  'LHFCALC': 'T',\n",
       "  'HFSCREEN': '0.20100000',\n",
       "  'PRECFOCK': 'fast'}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pivotpy.vr_parser as vp\n",
    "xml_data=vp.read_asxml(path= '../vasprun.xml')\n",
    "vp.get_summary(xml_data=xml_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_kpts(xml_data=None,skipk=0,joinPathAt=[]):\n",
    "    \"\"\"\n",
    "    - Returns kpoints and calculated kpath.\n",
    "    - **Parameters**\n",
    "        - xml_data   : From `read_asxml` function\n",
    "        - skipk      : Number of initil kpoints to skip\n",
    "        - joinPathAt : List of indices of kpoints where path is broken\n",
    "    - **Returns**\n",
    "        - dict     : Dictionary that contains kpoints ans kpath.\n",
    "    \"\"\"\n",
    "    if(xml_data==None):\n",
    "        xml_data=read_asxml()\n",
    "    if not xml_data:\n",
    "        return\n",
    "    import numpy as np\n",
    "    for kpts in xml_data.iter('varray'):\n",
    "        if(kpts.attrib=={'name': 'kpointlist'}):\n",
    "            kpoints=[[float(item) for item in arr.text.split()] for arr in kpts.iter('v')]\n",
    "    kpoints=np.array(kpoints[skipk:])\n",
    "    #KPath solved.\n",
    "    kpath=[0];pts=kpoints\n",
    "    [kpath.append(np.round(np.sqrt(np.sum((pt1-pt2)**2))+kpath[-1],6)) for pt1,pt2 in zip(pts[:-1],pts[1:])]\n",
    "    # If broken path, then join points.\n",
    "    try:\n",
    "        joinPathAt\n",
    "    except NameError:\n",
    "        joinPathAt = []\n",
    "    if(joinPathAt):\n",
    "        for pt in joinPathAt:\n",
    "            kpath[pt:]=kpath[pt:]-kpath[pt]+kpath[pt-1]\n",
    "\n",
    "    return Dic2Dot({'NKPTS':len(kpoints),'kpoints':kpoints,'kpath':kpath})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['NKPTS', 'kpoints', 'kpath'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vp.get_kpts(xml_data=xml_data,skipk=10).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_tdos(xml_data=None,spin_set=1,elim=[]):\n",
    "    \"\"\"\n",
    "    - Returns total dos for a spin_set (default 1) and energy limit. If spin-polarized calculations, gives SpinUp and SpinDown keys as well.\n",
    "    - **Parameters**\n",
    "        - xml_data : From `read_asxml` function\n",
    "        - spin_set : int, default is 1.and\n",
    "        - elim     : List [min,max] of energy, default empty.\n",
    "    - **Returns**\n",
    "        - dict     : Dictionary that contains E_Fermi, ISPIN,tdos.\n",
    "    \"\"\"\n",
    "    if(xml_data==None):\n",
    "        xml_data=read_asxml()\n",
    "    if not xml_data:\n",
    "        return\n",
    "    import numpy as np #Mandatory to avoid errors.\n",
    "    tdos=[]; #assign for safely exit if wrong spin set entered.\n",
    "    ISPIN=get_ispin(xml_data=xml_data)\n",
    "    for neighbor in xml_data.iter('dos'):\n",
    "        for item in neighbor[1].iter('set'):\n",
    "            if(ISPIN==1 and spin_set==1):\n",
    "                if(item.attrib=={'comment': 'spin 1'}):\n",
    "                    tdos=np.array([[float(entry) for entry in arr.text.split()] for arr in item])\n",
    "            if(ISPIN==2 and spin_set==1):\n",
    "                if(item.attrib=={'comment': 'spin 1'}):\n",
    "                    tdos_1=np.array([[float(entry) for entry in arr.text.split()] for arr in item])\n",
    "                if(item.attrib=={'comment': 'spin 2'}):\n",
    "                    tdos_2=np.array([[float(entry) for entry in arr.text.split()] for arr in item])\n",
    "                    tdos=Dic2Dot({'SpinUp':tdos_1,'SpinDown':tdos_2})\n",
    "            if(spin_set!=1): #can get any\n",
    "                if(item.attrib=={'comment': 'spin {}'.format(spin_set)}):\n",
    "                    tdos=np.array([[float(entry) for entry in arr.text.split()] for arr in item])\n",
    "    for i in xml_data.iter('i'): #efermi for condition required.\n",
    "        if(i.attrib=={'name': 'efermi'}):\n",
    "            efermi=float(i.text)\n",
    "    dos_dic=Dic2Dot({'E_Fermi':efermi,'ISPIN':ISPIN,'tdos':tdos})\n",
    "    #Filtering in energy range.\n",
    "    if elim: #check if elim not empty\n",
    "        if(ISPIN==1 and spin_set==1):\n",
    "            up_ind=np.max(np.where(tdos[:,0]-efermi<=np.max(elim)))+1\n",
    "            lo_ind=np.min(np.where(tdos[:,0]-efermi>=np.min(elim)))\n",
    "            tdos=tdos[lo_ind:up_ind,:]\n",
    "        if(ISPIN==2 and spin_set==1):\n",
    "            up_ind=np.max(np.where(tdos.SpinUp[:,0]-efermi<=np.max(elim)))+1\n",
    "            lo_ind=np.min(np.where(tdos.SpinUp[:,0]-efermi>=np.min(elim)))\n",
    "            tdos=Dic2Dot({'SpinUp':tdos_1[lo_ind:up_ind,:],'SpinDown':tdos_2[lo_ind:up_ind,:]})\n",
    "        if(spin_set!=1):\n",
    "            up_ind=np.max(np.where(tdos[:,0]-efermi<=np.max(elim)))+1\n",
    "            lo_ind=np.min(np.where(tdos[:,0]-efermi>=np.min(elim)))\n",
    "            tdos=tdos[lo_ind:up_ind,:]\n",
    "        dos_dic=Dic2Dot({'E_Fermi':efermi,'ISPIN':ISPIN,'grid_range':range(lo_ind,up_ind),'tdos':tdos})\n",
    "    return dos_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['E_Fermi', 'ISPIN', 'tdos'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vp.get_tdos(xml_data=xml_data,spin_set=1,elim=[]).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_evals(xml_data=None,skipk=None,elim=[]):\n",
    "    \"\"\"\n",
    "    - Returns eigenvalues as numpy array. If spin-polarized calculations, gives SpinUp and SpinDown keys as well.\n",
    "    - **Parameters**\n",
    "        - xml_data : From `read_asxml` function\n",
    "        - skipk    : Number of initil kpoints to skip.\n",
    "        - elim     : List [min,max] of energy, default empty.\n",
    "    - **Returns**\n",
    "        - dict     : Dictionary that contains evals and related parameters.\n",
    "    \"\"\"\n",
    "    if(xml_data==None):\n",
    "        xml_data=read_asxml()\n",
    "    if not xml_data:\n",
    "        return\n",
    "    import numpy as np #Mandatory to avoid errors.\n",
    "    evals=[]; #assign for safely exit if wrong spin set entered.\n",
    "    ISPIN=get_ispin(xml_data=xml_data)\n",
    "    if skipk!=None:\n",
    "        skipk=skipk\n",
    "    else:\n",
    "        skipk=exclude_kpts(xml_data=xml_data) #that much to skip by default\n",
    "    for neighbor in xml_data.iter('eigenvalues'):\n",
    "            for item in neighbor[0].iter('set'):\n",
    "                if(ISPIN==1):\n",
    "                    if(item.attrib=={'comment': 'spin 1'}):\n",
    "                        evals=np.array([[float(th.text.split()[0]) for th in thing] for thing in item])[skipk:]\n",
    "                        NBANDS=len(evals[0])\n",
    "                if(ISPIN==2):\n",
    "                    if(item.attrib=={'comment': 'spin 1'}):\n",
    "                        eval_1=np.array([[float(th.text.split()[0]) for th in thing] for thing in item])[skipk:]\n",
    "                    if(item.attrib=={'comment': 'spin 2'}):\n",
    "                        eval_2=np.array([[float(th.text.split()[0]) for th in thing] for thing in item])[skipk:]\n",
    "                        evals=Dic2Dot({'SpinUp':eval_1,'SpinDown':eval_2})\n",
    "                        NBANDS=len(eval_1[0])\n",
    "\n",
    "    for i in xml_data.iter('i'): #efermi for condition required.\n",
    "        if(i.attrib=={'name': 'efermi'}):\n",
    "            efermi=float(i.text)\n",
    "    evals_dic=Dic2Dot({'E_Fermi':efermi,'ISPIN':ISPIN,'NBANDS':NBANDS,'evals':evals})\n",
    "    if elim: #check if elim not empty\n",
    "        if(ISPIN==1):\n",
    "            up_ind=np.max(np.where(evals[:,:]-efermi<=np.max(elim))[1])+1\n",
    "            lo_ind=np.min(np.where(evals[:,:]-efermi>=np.min(elim))[1])\n",
    "            evals=evals[:,lo_ind:up_ind]\n",
    "        if(ISPIN==2):\n",
    "            up_ind=np.max(np.where(eval_1[:,:]-efermi<=np.max(elim))[1])+1\n",
    "            lo_ind=np.min(np.where(eval_1[:,:]-efermi>=np.min(elim))[1])\n",
    "            evals=Dic2Dot({'SpinUp':eval_1[:,lo_ind:up_ind],'SpinDown':eval_2[:,lo_ind:up_ind]})\n",
    "        NBANDS=up_ind-lo_ind #update Bands\n",
    "        evals_dic=Dic2Dot({'E_Fermi':efermi,'ISPIN':ISPIN,'NBANDS': NBANDS,'bands_range':range(lo_ind,up_ind),'evals':evals})\n",
    "    return evals_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['E_Fermi', 'ISPIN', 'NBANDS', 'bands_range', 'evals'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "range(1, 8)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(vp.get_evals(xml_data=xml_data,skipk=10,elim=[-5,5]).keys())\n",
    "vp.get_evals(xml_data=xml_data,skipk=10,elim=[-5,5]).bands_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_bands_pro_set(xml_data=None,spin_set=1,skipk=0,bands_range=None):\n",
    "    \"\"\"\n",
    "    - Returns bands projection of a spin_set(default 1) as numpy array. If spin-polarized calculations, gives SpinUp and SpinDown keys as well.\n",
    "    - **Parameters**\n",
    "        - xml_data    : From `read_asxml` function\n",
    "        - skipk       : Number of initil kpoints to skip (Default 0).\n",
    "        - spin_set    : Spin set to get, default is 1.\n",
    "        - bands_range : If elim used in `get_evals`,that will return bands_range to use here..\n",
    "    - **Returns**\n",
    "        - dict     : Dictionary that contains bands projections and related parameters.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import pivotpy.g_utils as gu\n",
    "    if(bands_range!=None):\n",
    "        check_list=list(bands_range)\n",
    "        if(check_list==[]):\n",
    "            return gu.printr(\"No bands prjections found in given energy range.\")\n",
    "    if(xml_data==None):\n",
    "        xml_data=read_asxml()\n",
    "    if not xml_data:\n",
    "        return\n",
    "    #Collect Projection fields\n",
    "    fields=[];\n",
    "    for pro in xml_data.iter('projected'):\n",
    "        for arr in pro.iter('field'):\n",
    "            if('eig' not in arr.text and 'occ' not in arr.text):\n",
    "                fields.append(arr.text.strip())\n",
    "    #Get NIONS for reshaping data\n",
    "    n_ions=[int(atom.text) for atom in xml_data.iter('atoms')][0]\n",
    "    #check if bands_range provided. if not get all bands in projection.\n",
    "    if bands_range==None:\n",
    "        NBANDS=get_evals(xml_data=xml_data,skipk=skipk).NBANDS\n",
    "        bands_range=range(0,NBANDS)\n",
    "    else:\n",
    "        bands_range=bands_range\n",
    "\n",
    "    bands=[];bands_range=[ind+1 for ind in bands_range];\n",
    "    for i in bands_range: #Bands loop.index written from 1.\n",
    "        pro=[];\n",
    "        for spin in xml_data.iter('set'):\n",
    "            if(spin.attrib=={'comment': 'spin{}'.format(spin_set)}):\n",
    "                for band in spin.iter('set'):\n",
    "                    if(band.attrib=={'comment': 'band {}'.format(i)}):\n",
    "                        for r in band.iter('r'):\n",
    "                            pro.append(r.text)\n",
    "        bands.append(pro)\n",
    "    flist=[[[float(item) for item in entry.split()] for entry in pro] for pro in bands]\n",
    "    #data shape is (NION,NKPTS,NBANDS,nProjections)\n",
    "    data=np.reshape(flist,(len(flist),-1,n_ions,len(fields))).transpose([2,1,0,3])\n",
    "    final_data=data[:,skipk:,:,:] #skip useless kpoints\n",
    "    return Dic2Dot({'labels':fields,'pros':final_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': ['s', 'py', 'pz', 'px', 'dxy', 'dyz', 'dz2', 'dxz', 'x2-y2'],\n",
       " 'pros': array([[[[0.09  , 0.    , 0.    , 0.    , 0.    , 0.    , 0.    ,\n",
       "           0.    , 0.    ]]],\n",
       " \n",
       " \n",
       "        [[[0.4527, 0.    , 0.    , 0.    , 0.    , 0.    , 0.    ,\n",
       "           0.    , 0.    ]]]])}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vp.get_bands_pro_set(xml_data=xml_data,skipk=135,spin_set=1,bands_range=range(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_dos_pro_set(xml_data=None,spin_set=1,dos_range=None):\n",
    "    \"\"\"\n",
    "    - Returns dos projection of a spin_set(default 1) as numpy array. If spin-polarized calculations, gives SpinUp and SpinDown keys as well.\n",
    "    - **Parameters**\n",
    "        - xml_data    : From `read_asxml` function\n",
    "        - spin_set    : Spin set to get, default 1.\n",
    "        - dos_range   : If elim used in `get_tdos`,that will return dos_range to use here..\n",
    "    - **Returns**\n",
    "        - dict        : Dictionary that contains dos projections and related parameters.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import pivotpy.g_utils as gu\n",
    "    if(dos_range!=None):\n",
    "        check_list=list(dos_range)\n",
    "        if(check_list==[]):\n",
    "            return gu.printr(\"No DOS prjections found in given energy range.\")\n",
    "    if(xml_data==None):\n",
    "        xml_data=read_asxml()\n",
    "    if not xml_data:\n",
    "        return\n",
    "    n_ions=get_summary(xml_data=xml_data).NION\n",
    "    for pro in xml_data.iter('partial'):\n",
    "        dos_fields=[field.text.strip()for field in pro.iter('field')]\n",
    "        #Collecting projections.\n",
    "        dos_pro=[]; set_pro=[]; #set_pro=[] in case spin set does not exists\n",
    "        for ion in range(n_ions):\n",
    "            for node in pro.iter('set'):\n",
    "                if(node.attrib=={'comment': 'ion {}'.format(ion+1)}):\n",
    "                    for spin in node.iter('set'):\n",
    "                        if(spin.attrib=={'comment': 'spin {}'.format(spin_set)}):\n",
    "                            set_pro=[[float(entry) for entry in r.text.split()] for r in spin.iter('r')]\n",
    "            dos_pro.append(set_pro)\n",
    "    if dos_range==None: #full grid computed.\n",
    "        dos_pro=np.array(dos_pro) #shape(NION,e_grid,pro_fields)\n",
    "    else:\n",
    "        dos_range=list(dos_range)\n",
    "        min_ind=dos_range[0]\n",
    "        max_ind=dos_range[-1]+1\n",
    "        dos_pro=np.array(dos_pro)[:,min_ind:max_ind,:]\n",
    "    final_data=np.array(dos_pro) #shape(NION,e_grid,pro_fields)\n",
    "    return Dic2Dot({'labels':dos_fields,'pros':final_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_structure(xml_data=None):\n",
    "    \"\"\"\n",
    "    - Returns structure's volume,basis,positions and rec-basis.\n",
    "    - **Parameters**\n",
    "        - xml_data : From `read_asxml` function\n",
    "    - **Returns**\n",
    "        - dict     : Dictionary that contains volume,basis,positions and rec_basis.\n",
    "    \"\"\"\n",
    "    if(xml_data==None):\n",
    "        xml_data=read_asxml()\n",
    "    if not xml_data:\n",
    "        return\n",
    "    import numpy as np\n",
    "    for final in xml_data.iter('structure'):\n",
    "        if(final.attrib=={'name': 'finalpos'}):\n",
    "            for i in final.iter('i'):\n",
    "                volume=float(i.text)\n",
    "            for arr in final.iter('varray'):\n",
    "                if(arr.attrib=={'name': 'basis'}):\n",
    "                    basis=[[float(a) for a in v.text.split()] for v in arr.iter('v')]\n",
    "                if(arr.attrib=={'name': 'rec_basis'}):\n",
    "                    rec_basis=[[float(a) for a in v.text.split()] for v in arr.iter('v')]\n",
    "                if(arr.attrib=={'name': 'positions'}):\n",
    "                    positions=[[float(a) for a in v.text.split()] for v in arr.iter('v')]\n",
    "    st_dic={'volume': volume,'basis': np.array(basis),'rec_basis': np.array(rec_basis),'positions': np.array(positions)}\n",
    "    return Dic2Dot(st_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['volume', 'basis', 'rec_basis', 'positions'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vp.get_structure(xml_data=xml_data).keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Export for Bandstructure\n",
    "A fully comprehensive command that uses all functions and returns data for spin set 1 (set 1 and 2 if spin-polarized calculations) could be constructed for immediate usage. It is `export_vasrun()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def export_vasprun(path=None,skipk=None,elim=[],joinPathAt=[],shift_kpath=0):\n",
    "    \"\"\"\n",
    "    - Returns a full dictionary of all objects from `vasprun.xml` file.\n",
    "    - **Parameters**\n",
    "        - path       : Path to `vasprun.xml` file. Default is `'./vasprun.xml'`.\n",
    "        - skipk      : Default is None. Automatically detects kpoints to skip.\n",
    "        - elim       : List [min,max] of energy interval. Default is [], covers all bands.\n",
    "        - joinPathAt : List of indices of kpoints where path is broken.\n",
    "        - shift_kpath: Default 0. Can be used to merge multiple calculations on single axes side by side.\n",
    "    - **Returns**\n",
    "        - dict : Dictionary accessible via dot notation containing objects:\n",
    "            - sys_info  : System Information\n",
    "            - dim_info  : Contains information about dimensions of returned objects.\n",
    "            - kpoints   : numpy array of kpoints with excluded IBZKPT points\n",
    "            - kpath     : 1D numpy array directly accessible for plot.\n",
    "            - bands     : Dictionary containing bands.\n",
    "            - tdos      : Dictionary containing total dos.\n",
    "            - pro_bands : Dictionary containing bands projections.\n",
    "            - pro_dos   : Dictionary containing dos projections.\n",
    "            - poscar    : containing basis,positions, rec_basis and volume.\n",
    "            - xml       : xml root object which is iterable over nodes using xml.iter('node').\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import pivotpy.vr_parser as vp\n",
    "    if(path==None):\n",
    "        xml_data=vp.read_asxml(path='./vasprun.xml')\n",
    "    else:\n",
    "        xml_data=vp.read_asxml(path=path)\n",
    "    if not xml_data:\n",
    "        return\n",
    "    #First exclude unnecessary kpoints. Includes only same weight points\n",
    "    if skipk!=None:\n",
    "        skipk=skipk\n",
    "    else:\n",
    "        skipk=vp.exclude_kpts(xml_data=xml_data) #that much to skip by default\n",
    "    info_dic=vp.get_summary(xml_data=xml_data) #Reads important information of system.\n",
    "    #KPOINTS\n",
    "    kpts=vp.get_kpts(xml_data=xml_data,skipk=skipk,joinPathAt=joinPathAt)\n",
    "    #EIGENVALS\n",
    "    eigenvals=vp.get_evals(xml_data=xml_data,skipk=skipk,elim=elim)\n",
    "    #TDOS\n",
    "    tot_dos=vp.get_tdos(xml_data=xml_data,spin_set=1,elim=elim)\n",
    "    #Bands and DOS Projection\n",
    "    if elim:\n",
    "        bands_range=eigenvals.bands_range\n",
    "        grid_range=tot_dos.grid_range\n",
    "    else:\n",
    "        bands_range=None #projection function will read itself.\n",
    "        grid_range=None\n",
    "    if(info_dic.ISPIN==1):\n",
    "        pro_bands=vp.get_bands_pro_set(xml_data=xml_data,spin_set=1,skipk=skipk,bands_range=bands_range)\n",
    "        pro_dos=vp.get_dos_pro_set(xml_data=xml_data,spin_set=1,dos_range=grid_range)\n",
    "    if(info_dic.ISPIN==2):\n",
    "        pro_1=vp.get_bands_pro_set(xml_data=xml_data,spin_set=1,skipk=skipk,bands_range=bands_range)\n",
    "        pro_2=vp.get_bands_pro_set(xml_data=xml_data,spin_set=2,skipk=skipk,bands_range=bands_range)\n",
    "        pros=Dic2Dot({'SpinUp': pro_1.pros,'SpinDown': pro_2.pros}) #accessing spins in dictionary after .pro.\n",
    "        pro_bands=Dic2Dot({'labels':pro_1.labels,'pros': pros})\n",
    "        pdos_1=vp.get_dos_pro_set(xml_data=xml_data,spin_set=1,dos_range=grid_range)\n",
    "        pdos_2=vp.get_dos_pro_set(xml_data=xml_data,spin_set=1,dos_range=grid_range)\n",
    "        pdos=vp.Dic2Dot({'SpinUp': pdos_1.pros,'SpinDown': pdos_2.pros}) #accessing spins in dictionary after .pro.\n",
    "        pro_dos=vp.Dic2Dot({'labels':pdos_1.labels,'pros': pdos})\n",
    "\n",
    "    #Structure\n",
    "    poscar=vp.get_structure(xml_data=xml_data)\n",
    "    #Dimensions dictionary.\n",
    "    dim_dic=vp.Dic2Dot({'⇅':'Each of SpinUp/SpinDown Arrays','kpoints':'(NKPTS,3)','kpath':'(NKPTS,1)','bands':'⇅(NKPTS,NBANDS)','dos':'⇅(grid_size,3)','pro_dos':'⇅(NION,grid_size,en+pro_fields)','pro_bands':'⇅(NION,NKPTS,NBANDS,pro_fields)'})\n",
    "    #Writing everything to be accessible via dot notation\n",
    "    kpath=[k+shift_kpath for k in kpts.kpath]  # shift kpath for side by side calculations.\n",
    "    full_dic={'sys_info':vp.Dic2Dot(info_dic),'dim_info':dim_dic,'kpoints':kpts.kpoints,'kpath':kpath,'bands':eigenvals,\n",
    "             'tdos':tot_dos,'pro_bands':pro_bands,'pro_dos':pro_dos,'poscar': poscar,'xml':xml_data}\n",
    "    return vp.Dic2Dot(full_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sys_info', 'dim_info', 'kpoints', 'kpath', 'bands', 'tdos', 'pro_bands', 'pro_dos', 'poscar', 'xml'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pivotpy as pp\n",
    "pp.export_vasprun(path='../vasprun.xml',elim=[-1,0]).keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining Multiple Calculations\n",
    "- Sometimes one may need to compare two or more bandstructures in same figure, for that reason, it is easy to export two calculations and plot on same axis.\n",
    "- There is another situation, if you have a large supercell and split calculations into multiple ones, joining that calculations works same way, you will add the last value of first kpath into all values of next kpath and next last to next and so on, by just using `shift_kpath` in `export_vasprun` and plot each export on same axis, this will align bandstructures side by side on same axis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Exported Vasprun from PowerShell\n",
    "On Windows, it will work automatically. On Linux/Mac it may require path to powershell executable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def load_export(path= './vasprun.xml',\n",
    "                joinPathAt =[],\n",
    "                shift_kpath = 0,\n",
    "                path_to_ps='pwsh',\n",
    "                skipk = None,\n",
    "                max_filled = 10,\n",
    "                max_empty = 10,\n",
    "                keep_files = True\n",
    "                ):\n",
    "    \"\"\"\n",
    "    - Returns a full dictionary of all objects from `vasprun.xml` file exported using powershell.\n",
    "    - **Parameters**\n",
    "        - path       : Path to `vasprun.xml` file. Default is `'./vasprun.xml'`.\n",
    "        - skipk      : Default is None. Automatically detects kpoints to skip.\n",
    "        - path_to_ps : Path to `powershell.exe`. Automatically picks on Windows and Linux if added to PATH.\n",
    "        - joinPathAt : List of indices of kpoints where path is broken.\n",
    "        - shift_kpath: Default 0. Can be used to merge multiple calculations side by side.\n",
    "        - keep_files : Could be use to clean exported text files. Default is True.\n",
    "        - max_filled : Number of filled bands below and including VBM. Default is 10.\n",
    "        - max_empty  : Number of empty bands above VBM. Default is 10.\n",
    "    - **Returns**\n",
    "        - dict : Dictionary accessible via dot notation containing objects:\n",
    "            - sys_info  : System Information\n",
    "            - dim_info  : Contains information about dimensions of returned objects.\n",
    "            - kpoints   : numpy array of kpoints with excluded IBZKPT points\n",
    "            - kpath     : 1D numpy array directly accessible for plot.\n",
    "            - bands     : Dictionary containing bands.\n",
    "            - tdos      : Dictionary containing total dos.\n",
    "            - pro_bands : Dictionary containing bands projections.\n",
    "            - pro_dos   : Dictionary containing dos projections.\n",
    "            - poscar    : containing basis,positions, rec_basis and volume.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import importlib as il\n",
    "    import pivotpy as pp\n",
    "    import pivotpy.vr_parser as vp\n",
    "    this_loc = os.getcwd()\n",
    "    split_path= os.path.split(path)\n",
    "    file_name = split_path[1]\n",
    "    that_loc = split_path[0]\n",
    "    # Go there.\n",
    "    os.chdir(that_loc)\n",
    "    # Work Here\n",
    "    i = 0\n",
    "    required_files = ['Bands.txt','tDOS.txt','pDOS.txt','Projection.txt','SysInfo.py']\n",
    "    for _file in required_files:\n",
    "        if(os.path.isfile(_file)):\n",
    "           i=i+1\n",
    "    if(i<5):\n",
    "        if (skipk != None):\n",
    "            pp.ps_to_std(path_to_ps=path_to_ps,ps_command='Import-Module Vasp2Visual; Export-VR -InputFile {} -MaxFilled {} -MaxEmpty {} -SkipK {}'.format(path,max_filled,max_empty,skipk))\n",
    "        else:\n",
    "            pp.ps_to_std(path_to_ps=path_to_ps,ps_command='Import-Module Vasp2Visual; Export-VR -InputFile {} -MaxFilled {} -MaxEmpty {}'.format(path,max_filled,max_empty))\n",
    "\n",
    "    # Enable reloading SysInfo.py file.\n",
    "    import SysInfo\n",
    "    vars=il.reload(SysInfo)\n",
    "    SYSTEM            = vars.SYSTEM\n",
    "    NKPTS             = vars.NKPTS\n",
    "    NBANDS            = vars.NBANDS\n",
    "    NFILLED           = vars.NFILLED\n",
    "    TypeION           = vars.TypeION\n",
    "    NION              = vars.NION\n",
    "    nField_Projection = vars.nField_Projection\n",
    "    E_Fermi           = vars.E_Fermi\n",
    "    ISPIN             = vars.ISPIN\n",
    "    ElemIndex         = vars.ElemIndex\n",
    "    ElemName          = vars.ElemName\n",
    "    poscar            = pp.Dic2Dot({\n",
    "                                    'volume':vars.volume,\n",
    "                                    'basis' :vars.basis,\n",
    "                                    'rec_basis':vars.rec_basis,\n",
    "                                    'positions':vars.positions\n",
    "                                    })\n",
    "    fields            = vars.fields\n",
    "    incar             = pp.Dic2Dot(vars.INCAR)\n",
    "    # Load Data\n",
    "    bands= np.loadtxt('Bands.txt').reshape((-1,NBANDS+4)) #Must be read in 2D even if one row only.\n",
    "    pro_bands= np.loadtxt('Projection.txt').reshape((-1,NBANDS*nField_Projection))\n",
    "    pro_dos = np.loadtxt('pDOS.txt')\n",
    "    dos= np.loadtxt('tDOS.txt')\n",
    "\n",
    "    # Keep or delete only if python generates files (i < 5 case.)\n",
    "    if(keep_files==False and i==5):\n",
    "        for file in required_files:\n",
    "            os.remove(file)\n",
    "    # Return back\n",
    "    os.chdir(this_loc)\n",
    "\n",
    "    # Work now!\n",
    "    sys_info = vp.Dic2Dot({'SYSTEM': SYSTEM,'NION': NION,'TypeION': TypeION,'ElemName': ElemName, 'E_Fermi': E_Fermi,'fields':fields, 'incar': incar,\n",
    "               'ElemIndex': ElemIndex,'ISPIN': ISPIN})\n",
    "    dim_info = vp.Dic2Dot({'⇅':'Each of SpinUp/SpinDown Arrays','kpoints': '(NKPTS,3)','kpath': '(NKPTS,1)','bands': '⇅(NKPTS,NBANDS)',\n",
    "'dos': '⇅(grid_size,3)','pro_dos': '⇅(NION,grid_size,en+pro_fields)','pro_bands': '⇅(NION,NKPTS,NBANDS,pro_fields)'})\n",
    "\n",
    "    bands_dic,tdos_dic,pdos_dic,pro_dic,kpath={},{},{},{},[]\n",
    "    if(ISPIN==1):\n",
    "        kpath   = bands[:,3]\n",
    "        kpoints = bands[:,:3]\n",
    "        evals   = bands[:,4:]\n",
    "        bands_dic = vp.Dic2Dot({'E_Fermi': E_Fermi, 'ISPIN': ISPIN, 'NBANDS': NBANDS, 'evals': evals})\n",
    "        tdos_dic  = vp.Dic2Dot({'E_Fermi': E_Fermi, 'ISPIN': ISPIN,'tdos': dos})\n",
    "        pdos      = pro_dos.reshape(NION,-1,nField_Projection+1)\n",
    "        pdos_dic  = vp.Dic2Dot({'labels': fields,'pros': pdos})\n",
    "        pros      = pro_bands.reshape(NION,NKPTS,NBANDS,-1)\n",
    "        pro_dic   = vp.Dic2Dot({'labels': fields[1:],'pros': pros})\n",
    "    if(ISPIN==2):\n",
    "        # Bands\n",
    "        kpath   = bands[:NKPTS,3]\n",
    "        kpoints = bands[:NKPTS,:3]\n",
    "        SpinUp  = bands[:NKPTS,4:]\n",
    "        SpinDown= bands[NKPTS:,4:]\n",
    "        evals   = vp.Dic2Dot({'SpinUp':SpinUp,'SpinDown': SpinDown})\n",
    "        bands_dic = vp.Dic2Dot({'E_Fermi': E_Fermi, 'ISPIN': ISPIN, 'NBANDS': NBANDS, 'evals': evals})\n",
    "        # tDOS\n",
    "        dlen    = int(np.shape(dos)[0]/2)\n",
    "        SpinUp  = dos[:dlen,:]\n",
    "        SpinDown= dos[dlen:,:]\n",
    "        tdos    = vp.Dic2Dot({'SpinUp':SpinUp,'SpinDown': SpinDown})\n",
    "        tdos_dic= vp.Dic2Dot({'E_Fermi': E_Fermi, 'ISPIN': ISPIN,'tdos': tdos})\n",
    "\n",
    "        # pDOS\n",
    "        plen    = int(np.shape(pro_dos)[0]/2)\n",
    "        SpinUp  = pro_dos[:plen,:].reshape(NION,-1,nField_Projection+1)\n",
    "        SpinDown= pro_dos[plen:,:].reshape(NION,-1,nField_Projection+1)\n",
    "        pdos    = vp.Dic2Dot({'SpinUp':SpinUp,'SpinDown': SpinDown})\n",
    "        pdos_dic= vp.Dic2Dot({'labels': fields,'pros': pdos})\n",
    "\n",
    "        # projections\n",
    "        pblen  = int(np.shape(pro_bands)[0]/2)\n",
    "        SpinUp  = pro_bands[:pblen,:].reshape(NION,NKPTS,NBANDS,-1)\n",
    "        SpinDown= pro_bands[pblen:,:].reshape(NION,NKPTS,NBANDS,-1)\n",
    "        pros    = vp.Dic2Dot({'SpinUp': SpinUp,'SpinDown': SpinDown})\n",
    "        pro_dic = vp.Dic2Dot({'labels': fields[1:],'pros': pros})\n",
    "    # If broken path, then join points.\n",
    "    try:\n",
    "        joinPathAt\n",
    "    except NameError:\n",
    "        joinPathAt = []\n",
    "    if(joinPathAt):\n",
    "        for pt in joinPathAt:\n",
    "            kpath[pt:]=kpath[pt:]-kpath[pt]+kpath[pt-1]\n",
    "    kpath=[k+shift_kpath for k in kpath.copy()] # Shift kpath\n",
    "    full_dic = vp.Dic2Dot({'sys_info': sys_info,'dim_info': dim_info,'kpoints': kpoints,'kpath':kpath,               'bands':bands_dic,'tdos':tdos_dic,'pro_bands': pro_dic ,'pro_dos': pdos_dic,\n",
    "               'poscar':poscar})\n",
    "    return full_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def make_dot_dict(json_loaded):\n",
    "    \"\"\"\n",
    "    - Returns a pivotpy.Dic2Dot object recursively and makes keys accessible via dot notation. Works only upto 4 nesting levels because it is basically created for vasprun data transfer back and forth in `pivotpy-dash` app.\n",
    "    - **Parameters**\n",
    "        - json_load : Output of json.load/json.loads or any python dictionary.\n",
    "    \"\"\"\n",
    "    ndict = json_loaded\n",
    "    if type(ndict) is not dict:\n",
    "        return print(\"json_loaded expects a dictionary but {} given.\".format(type(ndict)))\n",
    "    import numpy as np\n",
    "    import pivotpy as pp\n",
    "    for key, value in ndict.items():\n",
    "        if type(value) is dict:\n",
    "            ndict[key] = pp.Dic2Dot(value)\n",
    "            for k1,v1 in value.items():\n",
    "                if type(v1) is dict:\n",
    "                    ndict[key][k1] = pp.Dic2Dot(v1)\n",
    "                    for k2,v2 in v1.items():\n",
    "                        if type(v2) is dict:\n",
    "                            ndict[key][k1][k2] = pp.Dic2Dot(v2)\n",
    "                            for k3,v3 in v2.items():\n",
    "                                if type(v3) is dict:\n",
    "                                    ndict[key][k1][k2][k3] = pp.Dic2Dot(v3)\n",
    "    return pp.Dic2Dot(ndict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL TYPE : <class 'pivotpy.vr_parser.Dic2Dot'>\n",
      "\n",
      "JSON DUMPED TYPE : <class 'str'>\n",
      "\n",
      "JSON LOADED TYPE : <class 'dict'>\n",
      "\n",
      "BACK TO ORIGINAL TYPE : <class 'pivotpy.vr_parser.Dic2Dot'>\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pivotpy as pp\n",
    "vr=pp.export_vasprun(path = \"E:/Research/graphene_example/ISPIN_2/bands/vasprun.xml\" ,elim=[0,5])\n",
    "vr.pop('xml',None) #Can't be serilized to json. \n",
    "print(\"ORIGINAL TYPE : {}\\n\".format(type(vr.poscar)))\n",
    "s=json.dumps(vr, cls=pp.EncodeFromNumpy)\n",
    "print(\"JSON DUMPED TYPE : {}\\n\".format(type(s)))\n",
    "s2 = json.loads(s, cls=pp.DecodeToNumpy)\n",
    "print(\"JSON LOADED TYPE : {}\\n\".format(type(s2)))\n",
    "s3= make_dot_dict(s2)\n",
    "print(\"BACK TO ORIGINAL TYPE : {}\".format(type(s3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make sure that data transfer between different formats does not result in loss of any information, we can check few things in start and end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "[ True  True  True  True]\n",
      "[ True  True  True]\n",
      "[ True  True  True  True  True  True  True  True  True  True]\n",
      "[ True  True  True  True  True  True  True  True  True]\n",
      "[[ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]]\n"
     ]
    }
   ],
   "source": [
    "print(vr.sys_info == s3.sys_info)\n",
    "print(vr.dim_info == s3.dim_info)\n",
    "print(vr.kpath == s3.kpath)\n",
    "print(vr.bands.evals.SpinUp[0] == s3.bands.evals.SpinUp[0])\n",
    "print(vr.tdos.tdos.SpinUp[0] == s3.tdos.tdos.SpinUp[0])\n",
    "print(vr.pro_dos.pros.SpinUp[0,0] == s3.pro_dos.pros.SpinUp[0,0])\n",
    "print(vr.pro_bands.pros.SpinUp[0,0,0] == s3.pro_bands.pros.SpinUp[0,0,0])\n",
    "print(vr.poscar.basis == s3.poscar.basis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This back and forth data transport is required in [pivotpy-dash](https://github.com/massgh/pivotpy-dash) app where data is stored in browser in json format, but needs to by python objects for figures.\n",
    "\n",
    "## Write Clean data to JSON or Pickle file\n",
    "Use `dump_vasprun` to write output of `export_vasprun` or `load_export` to pickle/json file. Pickle is useful for quick load in python while json is useful to transfer data into any language. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def dump_dict(dict_obj = None, dump_to = 'pickle',outfile = None):\n",
    "    \"\"\"\n",
    "    - Dump an `export_vasprun` or `load_export` object to json or pickle string/file.\n",
    "    - **Parameters**\n",
    "        - dict_obj : Any dictionary containg numpy arrays, including `export_vasprun` or `load_export` output.\n",
    "        - dump_to  : Defualt is `pickle` or `json`.\n",
    "        - outfile  : Defualt is None and return string. File name does not require extension.\n",
    "    \"\"\"\n",
    "    if dump_to not in ['pickle','json']:\n",
    "        return print(\"`dump_to` expects 'pickle' or 'json', got '{}'\".format(dump_to))\n",
    "    try: dict_obj.pop('xml',None)\n",
    "    except: pass\n",
    "\n",
    "    if dump_to == 'pickle':\n",
    "        import pickle\n",
    "        if outfile == None:\n",
    "            return pickle.dumps(dict_obj)\n",
    "        outfile = outfile.split('.')[0] + '.pickle'\n",
    "        f = open(outfile,'wb')\n",
    "        pickle.dump(dict_obj,f)\n",
    "        f.close()\n",
    "    if dump_to == 'json':\n",
    "        import json\n",
    "        from pivotpy.g_utils import EncodeFromNumpy\n",
    "        if outfile == None:\n",
    "            return json.dumps(dict_obj,cls=EncodeFromNumpy)\n",
    "        outfile = outfile.split('.')[0] + '.json'\n",
    "        f = open(outfile,'w')\n",
    "        json.dump(dict_obj,f,cls=EncodeFromNumpy)\n",
    "        f.close()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\x80\\x03}q\\x00X\\x04\\x00\\x00\\x00nameq\\x01X\\x06\\x00\\x00\\x00Saboorq\\x02s.'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"name\": \"Saboor\"}'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dump_dict({\"name\":\"Saboor\"}))\n",
    "dump_dict({\"name\":\"Saboor\"},'json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bit4047a33bb5c7414db9abe32ad88decaa"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
