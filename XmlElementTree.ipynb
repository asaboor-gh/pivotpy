{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp vr_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<style>a{text-decoration: none !important;color:lightkblue;font-weight:bold;}\n",
       "                a:focus,a:active,a:hover{color:hotpink !important;}</style>\n",
       "> [&nbsp;`▶` Index&nbsp;](https://massgh.github.io/pivotpy/)  \n",
       "> [&nbsp;`▶` XmlElementTree●&nbsp;](https://massgh.github.io/pivotpy/XmlElementTree)  \n",
       "> [&nbsp;`▶` StaticPlots&nbsp;](https://massgh.github.io/pivotpy/StaticPlots)  \n",
       "> [&nbsp;`▶` InteractivePlots&nbsp;](https://massgh.github.io/pivotpy/InteractivePlots)  \n",
       "> [&nbsp;`▶` Utilities&nbsp;](https://massgh.github.io/pivotpy/Utilities)  \n",
       "> [&nbsp;`▶` StructureIO&nbsp;](https://massgh.github.io/pivotpy/StructureIO)  \n",
       "> [&nbsp;`▶` Widgets&nbsp;](https://massgh.github.io/pivotpy/Widgets)  \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide_input\n",
    "import pivotpy as pp \n",
    "pp.nav_links(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xml Parser\n",
    "> This parser contains functions to extract data from vasprun.xml. All functions in xml parser can work without arguments if working directory contains `vasprun.xml`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Almost every object in this module returns a `Dict2Data` object with attributes accessible via dot notation. This object can by transformed to a dictionary by `to_dict()` method on the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy\n",
    "class Dict2Data(dict):\n",
    "    \"\"\"\n",
    "    - Returns a Data object with dictionary keys as attributes of Data accessible by dot notation.\n",
    "    - **Parmeters**\n",
    "        - dict : Python dictionary (nested as well) containing any python data types.\n",
    "    - **Attributes**\n",
    "        - to_dict() : Converts a Data object to dictionary if it could be made a dictionary, otherwise throws relevant error. \n",
    "    - **Example**\n",
    "        > x = Dict2Data({'A':1,'B':{'C':2}})\n",
    "        > x\n",
    "        > Data(\n",
    "        >     A = 1\n",
    "        >     B = Data(\n",
    "        >         C = 2\n",
    "        >         )\n",
    "        >     )\n",
    "        > x.B.to_dict()\n",
    "        > {'C': 2}\n",
    "    \"\"\"\n",
    "    def __init__(self,d):\n",
    "        if isinstance(d,Dict2Data):\n",
    "            d = d.to_dict() # if nested Dict2Dataects, must expand here.\n",
    "        for a,b in d.items():\n",
    "            if isinstance(b,Dict2Data):\n",
    "                b = b.to_dict() # expands self instance !must here.\n",
    "            if isinstance(b,(list,tuple)):\n",
    "                setattr(self,a,[Dict2Data(x) if isinstance(x,dict) else x for x in b])\n",
    "            else:\n",
    "                setattr(self,a,Dict2Data(b) if isinstance(b,dict) else b)\n",
    "    def to_dict(self):\n",
    "        \"\"\"\n",
    "        - Converts a `Dict2Data` object (root or nested level) to a dictionary.\n",
    "        \"\"\"\n",
    "        result = {}\n",
    "        for k,v in self.__dict__.items():\n",
    "            if isinstance(v,Dict2Data):\n",
    "                result.update({k:Dict2Data.to_dict(v)})\n",
    "            else:\n",
    "                result.update({k:v})\n",
    "        return result\n",
    "\n",
    "    def __repr__(self):\n",
    "        items= []\n",
    "        for k,v in self.__dict__.items():\n",
    "            if type(v) not in (str,float,int,range) and not isinstance(v,Dict2Data):\n",
    "                if isinstance(v,numpy.ndarray):\n",
    "                    v = \"<{}:shape={}>\".format(v.__class__.__name__,numpy.shape(v))\n",
    "                elif type(v) in (list,tuple):\n",
    "                    v = (\"<{}:len={}>\".format(v.__class__.__name__,len(v)) if len(v) > 10 else v)\n",
    "                else:\n",
    "                    v = v.__class__\n",
    "            if isinstance(v,Dict2Data):\n",
    "                v = repr(v).replace(\"\\n\",\"\\n    \")\n",
    "            items.append(f\"    {k} = {v}\")\n",
    "            \n",
    "        return \"Data(\\n{}\\n)\".format('\\n'.join(items))\n",
    "    def __getstate__(self):\n",
    "        pass  #This is for pickling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parser Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def read_asxml(path=None,suppress_warning=False):\n",
    "    \"\"\"\n",
    "    - Reads a big vasprun.xml file into memory once and then apply commands.\n",
    "    If current folder contains `vasprun.xml` file, it automatically picks it.\n",
    "\n",
    "    - **Parameters**\n",
    "        - path             : Path/To/vasprun.xml\n",
    "        - suppress_warning : False by defualt. Warns about memory usage for large files > 100 MB.\n",
    "    - **Returns**\n",
    "        - xml_data : Xml object to use in other functions\n",
    "    \"\"\"\n",
    "    if(path==None):\n",
    "        path='./vasprun.xml'\n",
    "    import xml.etree.ElementTree as ET\n",
    "    import os\n",
    "    if not os.path.isfile(path):\n",
    "        print(\"File: '{}'' does not exist!\".format(path))\n",
    "        return # This is important to stop further errors.\n",
    "    elif 'vasprun.xml' not in path:\n",
    "        print(\"File should end with 'vasprun.xml', prefixes are allowed.\")\n",
    "        return # This is important to stop further errors.\n",
    "    else:\n",
    "        if suppress_warning == False:\n",
    "            from pivotpy.g_utils import get_file_size,printy,printg\n",
    "            fsize = get_file_size(path)\n",
    "            value = float(fsize.split()[0])\n",
    "            print_str = \"\"\"\n",
    "            File: {} is large ({}).\n",
    "            It may consume a lot of memory (generally 3 times the file size).\n",
    "\n",
    "            An alternative way is to parse vasprun.xml is by using `Vasp2Visual` module in Powershell by command\n",
    "            `pivotpy.load_export('path/to/vasprun.xml'), which runs underlying powershell functions to load data whith\n",
    "            efficient memory managment. It works on Windows/Linux/MacOS if you have powershell core and Vasp2Visual\n",
    "            installed on it.\n",
    "\n",
    "            Hit `Ctrl+C` if you do not get `successful!` prompt in <10 sec, then use `load_export()` instead with\n",
    "            max_filled/max_empty given, default is 10/10 bands above and below VBM.\n",
    "            \"\"\".format(path,fsize)\n",
    "            if 'MB' in fsize and value > 100:\n",
    "                printy(print_str)\n",
    "            elif 'GB' in fsize and value > 1:\n",
    "                printy(print_str)\n",
    "                value = value*1024 # To show in MBs for later Use.\n",
    "         \n",
    "        tree = ET.parse(path)\n",
    "        xml_data = tree.getroot()\n",
    "        if suppress_warning == False and value > 100:\n",
    "            printg('\\n      successful!\\n')\n",
    "        return xml_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def exclude_kpts(xml_data=None):\n",
    "    \"\"\"\n",
    "    - Returns number of kpoints to exclude used from IBZKPT.\n",
    "    - **Parameters**\n",
    "        - xml_data : From `read_asxml` function\n",
    "    - **Returns**\n",
    "        - int      : Number of kpoints to exclude.\n",
    "    \"\"\"\n",
    "    if(xml_data==None):\n",
    "        xml_data=read_asxml()\n",
    "    if not xml_data:\n",
    "        return\n",
    "    for kpts in xml_data.iter('varray'):\n",
    "        if(kpts.attrib=={'name': 'weights'}):\n",
    "            weights=[float(arr.text.strip()) for arr in kpts.iter('v')]\n",
    "    exclude=[]\n",
    "    [exclude.append(item) for item in weights if item!=weights[-1]];\n",
    "    skipk=len(exclude) #that much to skip\n",
    "    return skipk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_ispin(xml_data=None):\n",
    "    \"\"\"\n",
    "    - Returns value of ISPIN.\n",
    "    - **Parameters**\n",
    "        - xml_data : From `read_asxml` function\n",
    "    - **Returns**\n",
    "        - int      : Value of ISPIN.\n",
    "    \"\"\"\n",
    "    if(xml_data==None):\n",
    "        xml_data=read_asxml()\n",
    "    if not xml_data:\n",
    "        return\n",
    "    for item in xml_data.iter('i'):\n",
    "        if(item.attrib=={'type': 'int', 'name': 'ISPIN'}):\n",
    "            return int(item.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_summary(xml_data=None):\n",
    "    \"\"\"\n",
    "    - Returns overview of system parameters.\n",
    "    - **Parameters**\n",
    "        - xml_data : From `read_asxml` function\n",
    "    - **Returns**\n",
    "        - Data     : pivotpy.Dict2Data with attibutes accessible via dot notation.\n",
    "    \"\"\"\n",
    "    if(xml_data==None):\n",
    "        xml_data=read_asxml()\n",
    "    if not xml_data:\n",
    "        return\n",
    "    for i_car in xml_data.iter('incar'):\n",
    "        incar={car.attrib['name']:car.text.strip() for car in i_car}\n",
    "    n_ions=[int(atom.text) for atom in xml_data.iter('atoms')][0]\n",
    "    type_ions=[int(atom_types.text) for atom_types in xml_data.iter('types')][0]\n",
    "    elem=[info[0].text.strip() for info in xml_data.iter('rc')]\n",
    "    elem_name=[]; #collect IONS names\n",
    "    [elem_name.append(item) for item in elem[:-type_ions] if item not in elem_name]\n",
    "    elem_index=[0]; #start index\n",
    "    [elem_index.append((int(entry)+elem_index[-1])) for entry in elem[-type_ions:]];\n",
    "    ISPIN=get_ispin(xml_data=xml_data)\n",
    "    # Fields\n",
    "    try:\n",
    "        for pro in xml_data.iter('partial'):\n",
    "            dos_fields=[field.text.strip() for field in pro.iter('field')]\n",
    "            dos_fields = [field for field in dos_fields if 'energy' not in field]\n",
    "    except:\n",
    "        dos_fields = []\n",
    "    for i in xml_data.iter('i'): #efermi for condition required.\n",
    "        if(i.attrib=={'name': 'efermi'}):\n",
    "            efermi=float(i.text)\n",
    "    #Writing information to a dictionary\n",
    "    info_dic={'SYSTEM':incar['SYSTEM'],'NION':n_ions,'TypeION':type_ions,'ElemName':elem_name,'ElemIndex':elem_index,\\\n",
    "        'E_Fermi': efermi,'ISPIN':ISPIN,'fields':dos_fields,'incar':incar}\n",
    "    return Dict2Data(info_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m \n",
      "      successful!\n",
      "\u001b[00m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(\n",
       "    SYSTEM = AlAs\n",
       "    NION = 2\n",
       "    TypeION = 2\n",
       "    ElemName = ['Al', 'As']\n",
       "    ElemIndex = [0, 1, 2]\n",
       "    E_Fermi = 3.72526782\n",
       "    ISPIN = 1\n",
       "    fields = ['s', 'py', 'pz', 'px', 'dxy', 'dyz', 'dz2', 'dxz', 'x2-y2']\n",
       "    incar = Data(\n",
       "        SYSTEM = AlAs\n",
       "        PREC = high\n",
       "        ALGO = N\n",
       "        NELMIN = 7\n",
       "        EDIFF = 0.00000100\n",
       "        ISMEAR = 0\n",
       "        SIGMA = 0.10000000\n",
       "        LORBIT = 11\n",
       "        KPOINT_BSE = -1     0     0     0\n",
       "        LHFCALC = T\n",
       "        HFSCREEN = 0.20100000\n",
       "        PRECFOCK = fast\n",
       "    )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pivotpy.vr_parser as vp\n",
    "xml_data=vp.read_asxml(path= '../vasprun.xml')\n",
    "get_summary(xml_data=xml_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_kpts(xml_data=None,skipk=0,joinPathAt=[]):\n",
    "    \"\"\"\n",
    "    - Returns kpoints and calculated kpath.\n",
    "    - **Parameters**\n",
    "        - xml_data   : From `read_asxml` function\n",
    "        - skipk      : Number of initil kpoints to skip\n",
    "        - joinPathAt : List of indices of kpoints where path is broken\n",
    "    - **Returns**\n",
    "        - Data     : pivotpy.Dict2Data with attibutes `kpath` and `kpoints`\n",
    "    \"\"\"\n",
    "    if(xml_data==None):\n",
    "        xml_data=read_asxml()\n",
    "    if not xml_data:\n",
    "        return\n",
    "    import numpy as np\n",
    "    for kpts in xml_data.iter('varray'):\n",
    "        if(kpts.attrib=={'name': 'kpointlist'}):\n",
    "            kpoints=[[float(item) for item in arr.text.split()] for arr in kpts.iter('v')]\n",
    "    kpoints=np.array(kpoints[skipk:])\n",
    "    #KPath solved.\n",
    "    kpath=[0];pts=kpoints\n",
    "    [kpath.append(np.round(np.sqrt(np.sum((pt1-pt2)**2))+kpath[-1],6)) for pt1,pt2 in zip(pts[:-1],pts[1:])]\n",
    "    # If broken path, then join points.\n",
    "    try:\n",
    "        joinPathAt\n",
    "    except NameError:\n",
    "        joinPathAt = []\n",
    "    if(joinPathAt):\n",
    "        for pt in joinPathAt:\n",
    "            kpath[pt:]=kpath[pt:]-kpath[pt]+kpath[pt-1]\n",
    "\n",
    "    return Dict2Data({'NKPTS':len(kpoints),'kpoints':kpoints,'kpath':kpath})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(\n",
       "    NKPTS = 126\n",
       "    kpoints = <ndarray:shape=(126, 3)>\n",
       "    kpath = <list:len=126>\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_kpts(xml_data=xml_data,skipk=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_tdos(xml_data=None,spin_set=1,elim=[]):\n",
    "    \"\"\"\n",
    "    - Returns total dos for a spin_set (default 1) and energy limit. If spin-polarized calculations, gives SpinUp and SpinDown keys as well.\n",
    "    - **Parameters**\n",
    "        - xml_data : From `read_asxml` function\n",
    "        - spin_set : int, default is 1.and\n",
    "        - elim     : List [min,max] of energy, default empty.\n",
    "    - **Returns**\n",
    "        - Data     : pivotpy.Dict2Data with attibutes E_Fermi, ISPIN,tdos.\n",
    "    \"\"\"\n",
    "    if(xml_data==None):\n",
    "        xml_data=read_asxml()\n",
    "    if not xml_data:\n",
    "        return\n",
    "    import numpy as np #Mandatory to avoid errors.\n",
    "    tdos=[]; #assign for safely exit if wrong spin set entered.\n",
    "    ISPIN=get_ispin(xml_data=xml_data)\n",
    "    for neighbor in xml_data.iter('dos'):\n",
    "        for item in neighbor[1].iter('set'):\n",
    "            if(ISPIN==1 and spin_set==1):\n",
    "                if(item.attrib=={'comment': 'spin 1'}):\n",
    "                    tdos=np.array([[float(entry) for entry in arr.text.split()] for arr in item])\n",
    "            if(ISPIN==2 and spin_set==1):\n",
    "                if(item.attrib=={'comment': 'spin 1'}):\n",
    "                    tdos_1=np.array([[float(entry) for entry in arr.text.split()] for arr in item])\n",
    "                if(item.attrib=={'comment': 'spin 2'}):\n",
    "                    tdos_2=np.array([[float(entry) for entry in arr.text.split()] for arr in item])\n",
    "                    tdos = {'SpinUp':tdos_1,'SpinDown':tdos_2}\n",
    "            if(spin_set!=1): #can get any\n",
    "                if(item.attrib=={'comment': 'spin {}'.format(spin_set)}):\n",
    "                    tdos=np.array([[float(entry) for entry in arr.text.split()] for arr in item])\n",
    "    for i in xml_data.iter('i'): #efermi for condition required.\n",
    "        if(i.attrib=={'name': 'efermi'}):\n",
    "            efermi=float(i.text)\n",
    "    dos_dic= {'E_Fermi':efermi,'ISPIN':ISPIN,'tdos':tdos}\n",
    "    #Filtering in energy range.\n",
    "    if elim: #check if elim not empty\n",
    "        if(ISPIN==1 and spin_set==1):\n",
    "            up_ind=np.max(np.where(tdos[:,0]-efermi<=np.max(elim)))+1\n",
    "            lo_ind=np.min(np.where(tdos[:,0]-efermi>=np.min(elim)))\n",
    "            tdos=tdos[lo_ind:up_ind,:]\n",
    "        if(ISPIN==2 and spin_set==1):\n",
    "            up_ind=np.max(np.where(tdos['SpinUp'][:,0]-efermi<=np.max(elim)))+1\n",
    "            lo_ind=np.min(np.where(tdos['SpinUp'][:,0]-efermi>=np.min(elim)))\n",
    "            tdos = {'SpinUp':tdos_1[lo_ind:up_ind,:],'SpinDown':tdos_2[lo_ind:up_ind,:]}\n",
    "        if(spin_set!=1):\n",
    "            up_ind=np.max(np.where(tdos[:,0]-efermi<=np.max(elim)))+1\n",
    "            lo_ind=np.min(np.where(tdos[:,0]-efermi>=np.min(elim)))\n",
    "            tdos=tdos[lo_ind:up_ind,:]\n",
    "        dos_dic= {'E_Fermi':efermi,'ISPIN':ISPIN,'grid_range':range(lo_ind,up_ind),'tdos':tdos}\n",
    "    return Dict2Data(dos_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(\n",
       "    E_Fermi = 3.72526782\n",
       "    ISPIN = 1\n",
       "    tdos = <ndarray:shape=(301, 3)>\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_tdos(xml_data=xml_data,spin_set=1,elim=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_evals(xml_data=None,skipk=None,elim=[]):\n",
    "    \"\"\"\n",
    "    - Returns eigenvalues as numpy array. If spin-polarized calculations, gives SpinUp and SpinDown keys as well.\n",
    "    - **Parameters**\n",
    "        - xml_data : From `read_asxml` function\n",
    "        - skipk    : Number of initil kpoints to skip.\n",
    "        - elim     : List [min,max] of energy, default empty.\n",
    "    - **Returns**\n",
    "        - Data     : pivotpy.Dict2Data with attibutes evals and related parameters.\n",
    "    \"\"\"\n",
    "    if(xml_data==None):\n",
    "        xml_data=read_asxml()\n",
    "    if not xml_data:\n",
    "        return\n",
    "    import numpy as np #Mandatory to avoid errors.\n",
    "    evals=[]; #assign for safely exit if wrong spin set entered.\n",
    "    ISPIN=get_ispin(xml_data=xml_data)\n",
    "    if skipk!=None:\n",
    "        skipk=skipk\n",
    "    else:\n",
    "        skipk=exclude_kpts(xml_data=xml_data) #that much to skip by default\n",
    "    for neighbor in xml_data.iter('eigenvalues'):\n",
    "            for item in neighbor[0].iter('set'):\n",
    "                if(ISPIN==1):\n",
    "                    if(item.attrib=={'comment': 'spin 1'}):\n",
    "                        evals=np.array([[float(th.text.split()[0]) for th in thing] for thing in item])[skipk:]\n",
    "                        NBANDS=len(evals[0])\n",
    "                if(ISPIN==2):\n",
    "                    if(item.attrib=={'comment': 'spin 1'}):\n",
    "                        eval_1=np.array([[float(th.text.split()[0]) for th in thing] for thing in item])[skipk:]\n",
    "                    if(item.attrib=={'comment': 'spin 2'}):\n",
    "                        eval_2=np.array([[float(th.text.split()[0]) for th in thing] for thing in item])[skipk:]\n",
    "                        evals={'SpinUp':eval_1,'SpinDown':eval_2}\n",
    "                        NBANDS=len(eval_1[0])\n",
    "\n",
    "    for i in xml_data.iter('i'): #efermi for condition required.\n",
    "        if(i.attrib=={'name': 'efermi'}):\n",
    "            efermi=float(i.text)\n",
    "    evals_dic={'E_Fermi':efermi,'ISPIN':ISPIN,'NBANDS':NBANDS,'evals':evals}\n",
    "    if elim: #check if elim not empty\n",
    "        if(ISPIN==1):\n",
    "            up_ind=np.max(np.where(evals[:,:]-efermi<=np.max(elim))[1])+1\n",
    "            lo_ind=np.min(np.where(evals[:,:]-efermi>=np.min(elim))[1])\n",
    "            evals=evals[:,lo_ind:up_ind]\n",
    "        if(ISPIN==2):\n",
    "            up_ind=np.max(np.where(eval_1[:,:]-efermi<=np.max(elim))[1])+1\n",
    "            lo_ind=np.min(np.where(eval_1[:,:]-efermi>=np.min(elim))[1])\n",
    "            evals={'SpinUp':eval_1[:,lo_ind:up_ind],'SpinDown':eval_2[:,lo_ind:up_ind]}\n",
    "        NBANDS=up_ind-lo_ind #update Bands\n",
    "        evals_dic={'E_Fermi':efermi,'ISPIN':ISPIN,'NBANDS': int(NBANDS),'bands_range':range(lo_ind,up_ind),'evals':evals}\n",
    "    return Dict2Data(evals_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(\n",
       "    E_Fermi = 3.72526782\n",
       "    ISPIN = 1\n",
       "    NBANDS = 7\n",
       "    bands_range = range(1, 8)\n",
       "    evals = <ndarray:shape=(126, 7)>\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_evals(xml_data=xml_data,skipk=10,elim=[-5,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_bands_pro_set(xml_data=None,spin_set=1,skipk=0,bands_range=None):\n",
    "    \"\"\"\n",
    "    - Returns bands projection of a spin_set(default 1) as numpy array. If spin-polarized calculations, gives SpinUp and SpinDown keys as well.\n",
    "    - **Parameters**\n",
    "        - xml_data    : From `read_asxml` function\n",
    "        - skipk       : Number of initil kpoints to skip (Default 0).\n",
    "        - spin_set    : Spin set to get, default is 1.\n",
    "        - bands_range : If elim used in `get_evals`,that will return bands_range to use here..\n",
    "    - **Returns**\n",
    "        - Data     : pivotpy.Dict2Data with attibutes of bands projections and related parameters.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import pivotpy.g_utils as gu\n",
    "    if(bands_range!=None):\n",
    "        check_list=list(bands_range)\n",
    "        if(check_list==[]):\n",
    "            return gu.printr(\"No bands prjections found in given energy range.\")\n",
    "    if(xml_data==None):\n",
    "        xml_data=read_asxml()\n",
    "    if not xml_data:\n",
    "        return\n",
    "    #Collect Projection fields\n",
    "    fields=[];\n",
    "    for pro in xml_data.iter('projected'):\n",
    "        for arr in pro.iter('field'):\n",
    "            if('eig' not in arr.text and 'occ' not in arr.text):\n",
    "                fields.append(arr.text.strip())\n",
    "    #Get NIONS for reshaping data\n",
    "    n_ions=[int(atom.text) for atom in xml_data.iter('atoms')][0]\n",
    "    #check if bands_range provided. if not get all bands in projection.\n",
    "    if bands_range==None:\n",
    "        NBANDS=get_evals(xml_data=xml_data,skipk=skipk).NBANDS\n",
    "        bands_range=range(0,NBANDS)\n",
    "    else:\n",
    "        bands_range=bands_range\n",
    "\n",
    "    bands=[];bands_range=[ind+1 for ind in bands_range];\n",
    "    for i in bands_range: #Bands loop.index written from 1.\n",
    "        pro=[];\n",
    "        for spin in xml_data.iter('set'):\n",
    "            if(spin.attrib=={'comment': 'spin{}'.format(spin_set)}):\n",
    "                for band in spin.iter('set'):\n",
    "                    if(band.attrib=={'comment': 'band {}'.format(i)}):\n",
    "                        for r in band.iter('r'):\n",
    "                            pro.append(r.text)\n",
    "        bands.append(pro)\n",
    "    flist=[[[float(item) for item in entry.split()] for entry in pro] for pro in bands]\n",
    "    #data shape is (NION,NKPTS,NBANDS,nProjections)\n",
    "    data=np.reshape(flist,(len(flist),-1,n_ions,len(fields))).transpose([2,1,0,3])\n",
    "    final_data=data[:,skipk:,:,:] #skip useless kpoints\n",
    "    return Dict2Data({'labels':fields,'pros':final_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(\n",
       "    labels = ['s', 'py', 'pz', 'px', 'dxy', 'dyz', 'dz2', 'dxz', 'x2-y2']\n",
       "    pros = <ndarray:shape=(2, 1, 1, 9)>\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_bands_pro_set(xml_data=xml_data,skipk=135,spin_set=1,bands_range=range(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_dos_pro_set(xml_data=None,spin_set=1,dos_range=None):\n",
    "    \"\"\"\n",
    "    - Returns dos projection of a spin_set(default 1) as numpy array. If spin-polarized calculations, gives SpinUp and SpinDown keys as well.\n",
    "    - **Parameters**\n",
    "        - xml_data    : From `read_asxml` function\n",
    "        - spin_set    : Spin set to get, default 1.\n",
    "        - dos_range   : If elim used in `get_tdos`,that will return dos_range to use here..\n",
    "    - **Returns**\n",
    "        - Data     : pivotpy.Dict2Data with attibutes of dos projections and related parameters.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import pivotpy.g_utils as gu\n",
    "    if(dos_range!=None):\n",
    "        check_list=list(dos_range)\n",
    "        if(check_list==[]):\n",
    "            return gu.printr(\"No DOS prjections found in given energy range.\")\n",
    "    if(xml_data==None):\n",
    "        xml_data=read_asxml()\n",
    "    if not xml_data:\n",
    "        return\n",
    "    n_ions=get_summary(xml_data=xml_data).NION\n",
    "    for pro in xml_data.iter('partial'):\n",
    "        dos_fields=[field.text.strip()for field in pro.iter('field')]\n",
    "        #Collecting projections.\n",
    "        dos_pro=[]; set_pro=[]; #set_pro=[] in case spin set does not exists\n",
    "        for ion in range(n_ions):\n",
    "            for node in pro.iter('set'):\n",
    "                if(node.attrib=={'comment': 'ion {}'.format(ion+1)}):\n",
    "                    for spin in node.iter('set'):\n",
    "                        if(spin.attrib=={'comment': 'spin {}'.format(spin_set)}):\n",
    "                            set_pro=[[float(entry) for entry in r.text.split()] for r in spin.iter('r')]\n",
    "            dos_pro.append(set_pro)\n",
    "    if dos_range==None: #full grid computed.\n",
    "        dos_pro=np.array(dos_pro) #shape(NION,e_grid,pro_fields)\n",
    "    else:\n",
    "        dos_range=list(dos_range)\n",
    "        min_ind=dos_range[0]\n",
    "        max_ind=dos_range[-1]+1\n",
    "        dos_pro=np.array(dos_pro)[:,min_ind:max_ind,:]\n",
    "    final_data=np.array(dos_pro) #shape(NION,e_grid,pro_fields)\n",
    "    return Dict2Data({'labels':dos_fields,'pros':final_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_structure(xml_data=None):\n",
    "    \"\"\"\n",
    "    - Returns structure's volume,basis,positions and rec-basis.\n",
    "    - **Parameters**\n",
    "        - xml_data : From `read_asxml` function.\n",
    "    - **Returns**\n",
    "        - Data     : pivotpy.Dict2Data with attibutes volume,basis,positions and rec_basis.\n",
    "    \"\"\"\n",
    "    if(xml_data==None):\n",
    "        xml_data=read_asxml()\n",
    "    if not xml_data:\n",
    "        return\n",
    "    import numpy as np\n",
    "    for final in xml_data.iter('structure'):\n",
    "        if(final.attrib=={'name': 'finalpos'}):\n",
    "            for i in final.iter('i'):\n",
    "                volume=float(i.text)\n",
    "            for arr in final.iter('varray'):\n",
    "                if(arr.attrib=={'name': 'basis'}):\n",
    "                    basis=[[float(a) for a in v.text.split()] for v in arr.iter('v')]\n",
    "                if(arr.attrib=={'name': 'rec_basis'}):\n",
    "                    rec_basis=[[float(a) for a in v.text.split()] for v in arr.iter('v')]\n",
    "                if(arr.attrib=={'name': 'positions'}):\n",
    "                    positions=[[float(a) for a in v.text.split()] for v in arr.iter('v')]\n",
    "    st_dic={'volume': volume,'basis': np.array(basis),'rec_basis': np.array(rec_basis),'positions': np.array(positions)}\n",
    "    return Dict2Data(st_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(\n",
       "    volume = 45.73530449\n",
       "    basis = <ndarray:shape=(3, 3)>\n",
       "    rec_basis = <ndarray:shape=(3, 3)>\n",
       "    positions = <ndarray:shape=(2, 3)>\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_structure(xml_data=xml_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Export for Bandstructure\n",
    "A fully comprehensive command that uses all functions and returns data for spin set 1 (set 1 and 2 if spin-polarized calculations) could be constructed for immediate usage. It is `export_vasrun()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def export_vasprun(path=None,skipk=None,elim=[],joinPathAt=[],shift_kpath=0):\n",
    "    \"\"\"\n",
    "    - Returns a full dictionary of all objects from `vasprun.xml` file. It first try to load the data exported by powershell's `Export-VR(Vasprun)`, which is very fast for large files. It is recommended to export large files in powershell first.\n",
    "    - **Parameters**\n",
    "        - path       : Path to `vasprun.xml` file. Default is `'./vasprun.xml'`.\n",
    "        - skipk      : Default is None. Automatically detects kpoints to skip.\n",
    "        - elim       : List [min,max] of energy interval. Default is [], covers all bands.\n",
    "        - joinPathAt : List of indices of kpoints where path is broken.\n",
    "        - shift_kpath: Default 0. Can be used to merge multiple calculations on single axes side by side.\n",
    "    - **Returns**\n",
    "        - Data : Data accessible via dot notation containing nested Data objects:\n",
    "            - sys_info  : System Information\n",
    "            - dim_info  : Contains information about dimensions of returned objects.\n",
    "            - kpoints   : numpy array of kpoints with excluded IBZKPT points\n",
    "            - kpath     : 1D numpy array directly accessible for plot.\n",
    "            - bands     : Data containing bands.\n",
    "            - tdos      : Data containing total dos.\n",
    "            - pro_bands : Data containing bands projections.\n",
    "            - pro_dos   : Data containing dos projections.\n",
    "            - poscar    : Data containing basis,positions, rec_basis and volume.\n",
    "    \"\"\"\n",
    "    import numpy as np, os\n",
    "    import pivotpy.vr_parser as vp\n",
    "\n",
    "    # Try to get files if exported data in PowerShell.\n",
    "    req_files = ['Bands.txt','tDOS.txt','pDOS.txt','Projection.txt','SysInfo.py']\n",
    "    if path and os.path.isfile(path):\n",
    "        req_files = [os.path.join(os.path.dirname(os.path.abspath(path)),f) for f in req_files]\n",
    "    logic = [os.path.isfile(f) for f in req_files]\n",
    "    if not False in logic:\n",
    "        from IPython.display import clear_output\n",
    "        print('Loading from PowerShell Exported Data...')\n",
    "        clear_output(wait=True)\n",
    "        return vp.load_export(path=(path if path else './vasprun.xml'))\n",
    "    \n",
    "    # Proceed if not files from PWSH\n",
    "    if(path==None):\n",
    "        xml_data=vp.read_asxml(path='./vasprun.xml')\n",
    "    else:\n",
    "        xml_data=vp.read_asxml(path=path)\n",
    "    if not xml_data:\n",
    "        return\n",
    "    #First exclude unnecessary kpoints. Includes only same weight points\n",
    "    if skipk!=None:\n",
    "        skipk=skipk\n",
    "    else:\n",
    "        skipk=vp.exclude_kpts(xml_data=xml_data) #that much to skip by default\n",
    "    info_dic=vp.get_summary(xml_data=xml_data) #Reads important information of system.\n",
    "    #KPOINTS\n",
    "    kpts=vp.get_kpts(xml_data=xml_data,skipk=skipk,joinPathAt=joinPathAt)\n",
    "    #EIGENVALS\n",
    "    eigenvals=vp.get_evals(xml_data=xml_data,skipk=skipk,elim=elim)\n",
    "    #TDOS\n",
    "    tot_dos=vp.get_tdos(xml_data=xml_data,spin_set=1,elim=elim)\n",
    "    #Bands and DOS Projection\n",
    "    if elim:\n",
    "        bands_range=eigenvals.bands_range\n",
    "        grid_range=tot_dos.grid_range\n",
    "    else:\n",
    "        bands_range=None #projection function will read itself.\n",
    "        grid_range=None\n",
    "    if(info_dic.ISPIN==1):\n",
    "        pro_bands=vp.get_bands_pro_set(xml_data=xml_data,spin_set=1,skipk=skipk,bands_range=bands_range)\n",
    "        pro_dos=vp.get_dos_pro_set(xml_data=xml_data,spin_set=1,dos_range=grid_range)\n",
    "    if(info_dic.ISPIN==2):\n",
    "        pro_1=vp.get_bands_pro_set(xml_data=xml_data,spin_set=1,skipk=skipk,bands_range=bands_range)\n",
    "        pro_2=vp.get_bands_pro_set(xml_data=xml_data,spin_set=2,skipk=skipk,bands_range=bands_range)\n",
    "        pros={'SpinUp': pro_1.pros,'SpinDown': pro_2.pros}#accessing spins in dictionary after .pro.\n",
    "        pro_bands={'labels':pro_1.labels,'pros': pros}\n",
    "        pdos_1=vp.get_dos_pro_set(xml_data=xml_data,spin_set=1,dos_range=grid_range)\n",
    "        pdos_2=vp.get_dos_pro_set(xml_data=xml_data,spin_set=1,dos_range=grid_range)\n",
    "        pdos={'SpinUp': pdos_1.pros,'SpinDown': pdos_2.pros}#accessing spins in dictionary after .pro.\n",
    "        pro_dos={'labels':pdos_1.labels,'pros': pdos}\n",
    "\n",
    "    #Structure\n",
    "    poscar=vp.get_structure(xml_data=xml_data)\n",
    "    #Dimensions dictionary.\n",
    "    dim_dic={'⇅':'Each of SpinUp/SpinDown Arrays','kpoints':'(NKPTS,3)','kpath':'(NKPTS,1)','bands':'⇅(NKPTS,NBANDS)','dos':'⇅(grid_size,3)','pro_dos':'⇅(NION,grid_size,en+pro_fields)','pro_bands':'⇅(NION,NKPTS,NBANDS,pro_fields)'}\n",
    "    #Writing everything to be accessible via dot notation\n",
    "    kpath=[k+shift_kpath for k in kpts.kpath]  # shift kpath for side by side calculations.\n",
    "    full_dic={'sys_info':info_dic,'dim_info':dim_dic,'kpoints':kpts.kpoints,'kpath':kpath,'bands':eigenvals,\n",
    "             'tdos':tot_dos,'pro_bands':pro_bands,'pro_dos':pro_dos,'poscar': poscar}\n",
    "    return vp.Dict2Data(full_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(\n",
       "    sys_info = Data(\n",
       "        SYSTEM = C2\n",
       "        NION = 2\n",
       "        TypeION = 1\n",
       "        ElemName = ['C']\n",
       "        E_Fermi = -3.3501\n",
       "        fields = ['s', 'py', 'pz', 'px', 'dxy', 'dyz', 'dz2', 'dxz', 'x2-y2']\n",
       "        incar = Data(\n",
       "            SYSTEM = C2\n",
       "            PREC = high\n",
       "            ALGO = N\n",
       "            LSORBIT = T\n",
       "            NELMIN = 7\n",
       "            ISMEAR = 0\n",
       "            SIGMA = 0.10000000\n",
       "            LORBIT = 11\n",
       "            GGA = PS\n",
       "        )\n",
       "        ElemIndex = [0, 2]\n",
       "        ISPIN = 1\n",
       "    )\n",
       "    dim_info = Data(\n",
       "        ⇅ = Each of SpinUp/SpinDown Arrays\n",
       "        kpoints = (NKPTS,3)\n",
       "        kpath = (NKPTS,1)\n",
       "        bands = ⇅(NKPTS,NBANDS)\n",
       "        dos = ⇅(grid_size,3)\n",
       "        pro_dos = ⇅(NION,grid_size,en+pro_fields)\n",
       "        pro_bands = ⇅(NION,NKPTS,NBANDS,pro_fields)\n",
       "    )\n",
       "    kpoints = <ndarray:shape=(90, 3)>\n",
       "    kpath = <list:len=90>\n",
       "    bands = Data(\n",
       "        E_Fermi = -3.3501\n",
       "        ISPIN = 1\n",
       "        NBANDS = 21\n",
       "        evals = <ndarray:shape=(90, 21)>\n",
       "    )\n",
       "    tdos = Data(\n",
       "        E_Fermi = -3.3501\n",
       "        ISPIN = 1\n",
       "        tdos = <ndarray:shape=(301, 3)>\n",
       "    )\n",
       "    pro_bands = Data(\n",
       "        labels = ['py', 'pz', 'px', 'dxy', 'dyz', 'dz2', 'dxz', 'x2-y2']\n",
       "        pros = <ndarray:shape=(2, 90, 21, 9)>\n",
       "    )\n",
       "    pro_dos = Data(\n",
       "        labels = ['s', 'py', 'pz', 'px', 'dxy', 'dyz', 'dz2', 'dxz', 'x2-y2']\n",
       "        pros = <ndarray:shape=(2, 301, 10)>\n",
       "    )\n",
       "    poscar = Data(\n",
       "        volume = 105.49324928\n",
       "        basis = <ndarray:shape=(3, 3)>\n",
       "        rec_basis = <ndarray:shape=(3, 3)>\n",
       "        positions = <ndarray:shape=(2, 3)>\n",
       "    )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_vasprun(path='E:/Research/graphene_example/ISPIN_1/bands/vasprun.xml',elim=[-1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining Multiple Calculations\n",
    "- Sometimes one may need to compare two or more bandstructures in same figure, for that reason, it is easy to export two calculations and plot on same axis.\n",
    "- There is another situation, if you have a large supercell and split calculations into multiple ones, joining that calculations works same way, you will add the last value of first kpath into all values of next kpath and next last to next and so on, by just using `shift_kpath` in `export_vasprun` and plot each export on same axis, this will align bandstructures side by side on same axis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Exported Vasprun from PowerShell\n",
    "On Windows, it will work automatically. On Linux/Mac it may require path to powershell executable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def load_export(path= './vasprun.xml',\n",
    "                joinPathAt =[],\n",
    "                shift_kpath = 0,\n",
    "                path_to_ps='pwsh',\n",
    "                skipk = None,\n",
    "                max_filled = 10,\n",
    "                max_empty = 10,\n",
    "                keep_files = True\n",
    "                ):\n",
    "    \"\"\"\n",
    "    - Returns a full dictionary of all objects from `vasprun.xml` file exported using powershell.\n",
    "    - **Parameters**\n",
    "        - path       : Path to `vasprun.xml` file. Default is `'./vasprun.xml'`.\n",
    "        - skipk      : Default is None. Automatically detects kpoints to skip.\n",
    "        - path_to_ps : Path to `powershell.exe`. Automatically picks on Windows and Linux if added to PATH.\n",
    "        - joinPathAt : List of indices of kpoints where path is broken.\n",
    "        - shift_kpath: Default 0. Can be used to merge multiple calculations side by side.\n",
    "        - keep_files : Could be use to clean exported text files. Default is True.\n",
    "        - max_filled : Number of filled bands below and including VBM. Default is 10.\n",
    "        - max_empty  : Number of empty bands above VBM. Default is 10.\n",
    "    - **Returns**\n",
    "        - Data : Data accessible via dot notation containing nested Data objects:\n",
    "            - sys_info  : System Information\n",
    "            - dim_info  : Contains information about dimensions of returned objects.\n",
    "            - kpoints   : numpy array of kpoints with excluded IBZKPT points\n",
    "            - kpath     : 1D numpy array directly accessible for plot.\n",
    "            - bands     : Data containing bands.\n",
    "            - tdos      : Data containing total dos.\n",
    "            - pro_bands : Data containing bands projections.\n",
    "            - pro_dos   : Data containing dos projections.\n",
    "            - poscar    : Data containing basis,positions, rec_basis and volume.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import importlib as il\n",
    "    import pivotpy as pp\n",
    "    import pivotpy.vr_parser as vp\n",
    "    this_loc = os.getcwd()\n",
    "    split_path= os.path.split(os.path.abspath(path)) # abspath is important to split. \n",
    "    file_name = split_path[1]\n",
    "    that_loc = split_path[0]\n",
    "    # Go there.\n",
    "    os.chdir(that_loc)\n",
    "    # Work Here\n",
    "    i = 0\n",
    "    required_files = ['Bands.txt','tDOS.txt','pDOS.txt','Projection.txt','SysInfo.py']\n",
    "    for _file in required_files:\n",
    "        if(os.path.isfile(_file)):\n",
    "           i=i+1\n",
    "    if(i<5):\n",
    "        if (skipk != None):\n",
    "            pp.ps_to_std(path_to_ps=path_to_ps,ps_command='Import-Module Vasp2Visual; Export-VR -InputFile {} -MaxFilled {} -MaxEmpty {} -SkipK {}'.format(path,max_filled,max_empty,skipk))\n",
    "        else:\n",
    "            pp.ps_to_std(path_to_ps=path_to_ps,ps_command='Import-Module Vasp2Visual; Export-VR -InputFile {} -MaxFilled {} -MaxEmpty {}'.format(path,max_filled,max_empty))\n",
    "\n",
    "    # Enable reloading SysInfo.py file.\n",
    "    \n",
    "    #import SysInfo\n",
    "    #_vars = il.reload(SysInfo)\n",
    "    # Single Load instead\n",
    "    from importlib.machinery import SourceFileLoader \n",
    "    _vars = SourceFileLoader(\"SysInfo\", \"./SysInfo.py\").load_module()\n",
    "\n",
    "    SYSTEM            = _vars.SYSTEM\n",
    "    NKPTS             = _vars.NKPTS\n",
    "    NBANDS            = _vars.NBANDS\n",
    "    NFILLED           = _vars.NFILLED\n",
    "    TypeION           = _vars.TypeION\n",
    "    NION              = _vars.NION\n",
    "    nField_Projection = _vars.nField_Projection\n",
    "    E_Fermi           = _vars.E_Fermi\n",
    "    ISPIN             = _vars.ISPIN\n",
    "    ElemIndex         = _vars.ElemIndex\n",
    "    ElemName          = _vars.ElemName\n",
    "    poscar            = {\n",
    "                        'volume':_vars.volume,\n",
    "                        'basis' : np.array(_vars.basis),\n",
    "                        'rec_basis': np.array(_vars.rec_basis),\n",
    "                        'positions': np.array(_vars.positions)\n",
    "                        }\n",
    "    fields            = _vars.fields\n",
    "    incar             = _vars.INCAR\n",
    "    # Load Data\n",
    "    bands= np.loadtxt('Bands.txt').reshape((-1,NBANDS+4)) #Must be read in 2D even if one row only.\n",
    "    pro_bands= np.loadtxt('Projection.txt').reshape((-1,NBANDS*nField_Projection))\n",
    "    pro_dos = np.loadtxt('pDOS.txt')\n",
    "    dos= np.loadtxt('tDOS.txt')\n",
    "\n",
    "    # Keep or delete only if python generates files (i < 5 case.)\n",
    "    if(keep_files==False and i==5):\n",
    "        for file in required_files:\n",
    "            os.remove(file)\n",
    "    # Return back\n",
    "    os.chdir(this_loc)\n",
    "\n",
    "    # Work now!\n",
    "    sys_info = {'SYSTEM': SYSTEM,'NION': NION,'TypeION': TypeION,'ElemName': ElemName, 'E_Fermi': E_Fermi,'fields':fields, 'incar': incar,\n",
    "               'ElemIndex': ElemIndex,'ISPIN': ISPIN}\n",
    "    dim_info = {'⇅':'Each of SpinUp/SpinDown Arrays','kpoints': '(NKPTS,3)','kpath': '(NKPTS,1)','bands': '⇅(NKPTS,NBANDS)',\n",
    "'dos': '⇅(grid_size,3)','pro_dos': '⇅(NION,grid_size,en+pro_fields)','pro_bands': '⇅(NION,NKPTS,NBANDS,pro_fields)'}\n",
    "\n",
    "    bands_dic,tdos_dic,pdos_dic,pro_dic,kpath={},{},{},{},[]\n",
    "    if(ISPIN==1):\n",
    "        kpath   = bands[:,3]\n",
    "        kpoints = bands[:,:3]\n",
    "        evals   = bands[:,4:]\n",
    "        bands_dic = {'E_Fermi': E_Fermi, 'ISPIN': ISPIN, 'NBANDS': NBANDS, 'evals': evals}\n",
    "        tdos_dic  = {'E_Fermi': E_Fermi, 'ISPIN': ISPIN,'tdos': dos}\n",
    "        pdos      = pro_dos.reshape(NION,-1,nField_Projection+1)\n",
    "        pdos_dic  = {'labels': fields,'pros': pdos}\n",
    "        pros      = pro_bands.reshape(NION,NKPTS,NBANDS,-1)\n",
    "        pro_dic   = {'labels': fields[1:],'pros': pros}\n",
    "    if(ISPIN==2):\n",
    "        # Bands\n",
    "        kpath   = bands[:NKPTS,3]\n",
    "        kpoints = bands[:NKPTS,:3]\n",
    "        SpinUp  = bands[:NKPTS,4:]\n",
    "        SpinDown= bands[NKPTS:,4:]\n",
    "        evals   = {'SpinUp':SpinUp,'SpinDown': SpinDown}\n",
    "        bands_dic = {'E_Fermi': E_Fermi, 'ISPIN': ISPIN, 'NBANDS': NBANDS, 'evals': evals}\n",
    "        # tDOS\n",
    "        dlen    = int(np.shape(dos)[0]/2)\n",
    "        SpinUp  = dos[:dlen,:]\n",
    "        SpinDown= dos[dlen:,:]\n",
    "        tdos    = {'SpinUp':SpinUp,'SpinDown': SpinDown}\n",
    "        tdos_dic= {'E_Fermi': E_Fermi, 'ISPIN': ISPIN,'tdos': tdos}\n",
    "\n",
    "        # pDOS\n",
    "        plen    = int(np.shape(pro_dos)[0]/2)\n",
    "        SpinUp  = pro_dos[:plen,:].reshape(NION,-1,nField_Projection+1)\n",
    "        SpinDown= pro_dos[plen:,:].reshape(NION,-1,nField_Projection+1)\n",
    "        pdos    = {'SpinUp':SpinUp,'SpinDown': SpinDown}\n",
    "        pdos_dic= {'labels': fields,'pros': pdos}\n",
    "\n",
    "        # projections\n",
    "        pblen  = int(np.shape(pro_bands)[0]/2)\n",
    "        SpinUp  = pro_bands[:pblen,:].reshape(NION,NKPTS,NBANDS,-1)\n",
    "        SpinDown= pro_bands[pblen:,:].reshape(NION,NKPTS,NBANDS,-1)\n",
    "        pros    = {'SpinUp': SpinUp,'SpinDown': SpinDown}\n",
    "        pro_dic = {'labels': fields[1:],'pros': pros}\n",
    "    # If broken path, then join points.\n",
    "    try:\n",
    "        joinPathAt\n",
    "    except NameError:\n",
    "        joinPathAt = []\n",
    "    if(joinPathAt):\n",
    "        for pt in joinPathAt:\n",
    "            kpath[pt:]=kpath[pt:]-kpath[pt]+kpath[pt-1]\n",
    "    kpath=[k+shift_kpath for k in kpath.copy()] # Shift kpath\n",
    "    full_dic = {'sys_info': sys_info,'dim_info': dim_info,'kpoints': kpoints,'kpath':kpath,               'bands':bands_dic,'tdos':tdos_dic,'pro_bands': pro_dic ,'pro_dos': pdos_dic,\n",
    "               'poscar':poscar}\n",
    "    return Dict2Data(full_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This back and forth data transport is required in [pivotpy-dash](https://github.com/massgh/pivotpy-dash) app where data is stored in browser in json format, but needs to by python objects for figures.\n",
    "\n",
    "## Write Clean data to JSON or Pickle file\n",
    "Use `dump_vasprun` to write output of `export_vasprun` or `load_export` to pickle/json file. Pickle is useful for quick load in python while json is useful to transfer data into any language. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def dump_dict(dict_data = None, dump_to = 'pickle',outfile = None):\n",
    "    \"\"\"\n",
    "    - Dump an `export_vasprun` or `load_export`'s `Data` object or any dictionary to json or pickle string/file. It convert `Dict2Data` to dictionary before serializing to json/pickle, so json/pickle.loads() of converted Data would be a simple dictionary, pass that to `Dict2Data` to again make accessible via dot notation.\n",
    "    - **Parameters**\n",
    "        - dict_data : Any dictionary/Dict2Data object containg numpy arrays, including `export_vasprun` or `load_export` output.\n",
    "        - dump_to  : Defualt is `pickle` or `json`.\n",
    "        - outfile  : Defualt is None and return string. File name does not require extension.\n",
    "    \"\"\"\n",
    "    if dump_to not in ['pickle','json']:\n",
    "        return print(\"`dump_to` expects 'pickle' or 'json', got '{}'\".format(dump_to))\n",
    "    try: dict_obj = dict_data.to_dict() # Change Data object to dictionary\n",
    "    except: dict_obj = dict_data \n",
    "    if dump_to == 'pickle':\n",
    "        import pickle\n",
    "        if outfile == None:\n",
    "            return pickle.dumps(dict_obj)\n",
    "        outfile = outfile.split('.')[0] + '.pickle'\n",
    "        f = open(outfile,'wb')\n",
    "        pickle.dump(dict_obj,f)\n",
    "        f.close()\n",
    "    if dump_to == 'json': \n",
    "        import json\n",
    "        from pivotpy.g_utils import EncodeFromNumpy\n",
    "        if outfile == None:\n",
    "            return json.dumps(dict_obj,cls=EncodeFromNumpy)\n",
    "        outfile = outfile.split('.')[0] + '.json'\n",
    "        f = open(outfile,'w')\n",
    "        json.dump(dict_obj,f,cls=EncodeFromNumpy)\n",
    "        f.close()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def load_from_dump(file_or_str,keep_as_dict=False):\n",
    "    \"\"\"\n",
    "    - Loads a json/pickle dumped file or string by auto detecting it. \n",
    "    - **Parameters**\n",
    "        - file_or_str : Filename of pickl/json or their string. \n",
    "        - keep_as_dict: Defualt is False and return `Data` object. If True, returns dictionary.\n",
    "    \"\"\"\n",
    "    out = {}\n",
    "    import os,pickle,json,pivotpy as pp\n",
    "    if not isinstance(file_or_str,bytes):\n",
    "        try: #must try, else fails due to path length issue\n",
    "            if os.path.isfile(file_or_str):\n",
    "                if '.pickle' in file_or_str:\n",
    "                    with open(file_or_str,'rb') as f:\n",
    "                        out = pickle.load(f)\n",
    "                    f.close()\n",
    "                elif '.json' in file_or_str:\n",
    "                    with open(file_or_str,'r') as f:\n",
    "                        out = json.load(f,cls=pp.DecodeToNumpy)\n",
    "                    f.close()\n",
    "            else: out = json.loads(file_or_str,cls=pp.DecodeToNumpy)\n",
    "            # json.loads required in else and except both as long str > 260 causes issue in start of try block\n",
    "        except: out = json.loads(file_or_str,cls=pp.DecodeToNumpy)\n",
    "    elif isinstance(file_or_str,bytes):\n",
    "            out = pickle.loads(file_or_str)\n",
    "            \n",
    "    if type(out) is dict and keep_as_dict == False:\n",
    "        return Dict2Data(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m \n",
      "      successful!\n",
      "\u001b[00m\n"
     ]
    }
   ],
   "source": [
    "import pivotpy as pp \n",
    "evr = pp.export_vasprun('../vasprun.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(\n",
       "    volume = 45.73530449\n",
       "    basis = <ndarray:shape=(3, 3)>\n",
       "    rec_basis = <ndarray:shape=(3, 3)>\n",
       "    positions = <ndarray:shape=(2, 3)>\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = dump_dict(evr.poscar,dump_to='pickle')\n",
    "#print(s)\n",
    "load_from_dump(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<style>a{text-decoration: none !important;color:lightkblue;font-weight:bold;}\n",
       "                a:focus,a:active,a:hover{color:hotpink !important;}</style>\n",
       "> [&nbsp;`▶` Index&nbsp;](https://massgh.github.io/pivotpy/)  \n",
       "> [&nbsp;`▶` XmlElementTree●&nbsp;](https://massgh.github.io/pivotpy/XmlElementTree)  \n",
       "> [&nbsp;`▶` StaticPlots&nbsp;](https://massgh.github.io/pivotpy/StaticPlots)  \n",
       "> [&nbsp;`▶` InteractivePlots&nbsp;](https://massgh.github.io/pivotpy/InteractivePlots)  \n",
       "> [&nbsp;`▶` Utilities&nbsp;](https://massgh.github.io/pivotpy/Utilities)  \n",
       "> [&nbsp;`▶` StructureIO&nbsp;](https://massgh.github.io/pivotpy/StructureIO)  \n",
       "> [&nbsp;`▶` Widgets&nbsp;](https://massgh.github.io/pivotpy/Widgets)  \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide_input\n",
    "import pivotpy as pp \n",
    "pp.nav_links(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bit4047a33bb5c7414db9abe32ad88decaa"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
